{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bleding train set and valid set...\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "            oob_score=False, random_state=398, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "            oob_score=False, random_state=812, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "2 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "           oob_score=False, random_state=312, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "3 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "           oob_score=False, random_state=4018, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "4 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=800, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "5 AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=1,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=417, verbose=0, warm_start=False),\n",
      "          learning_rate=0.5, n_estimators=50, random_state=None)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "6 AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=1,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=2345, verbose=0, warm_start=False),\n",
      "          learning_rate=0.3, n_estimators=50, random_state=None)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "7 BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=1,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=50, n_jobs=1, oob_score=False,\n",
      "         random_state=1245, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "8 BaggingClassifier(base_estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=1,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=50, n_jobs=1, oob_score=False,\n",
      "         random_state=456, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "9 BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=200, n_jobs=-1, oob_score=False,\n",
      "         random_state=1556, verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "11 DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "12 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "13 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "14 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Blending models by logistic regression...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1207: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for (class_, warm_start_coef_) in zip(classes_, warm_start_coef))\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.949\n",
      "Best parameters set:\n",
      "\tclf__C: 0.7\n",
      "\tclf__solver: 'newton-cg'\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "import contest\n",
    "reload(contest)\n",
    "\n",
    "from contest import run_local, score\n",
    "\n",
    "score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from classifier import encode_onehot, encode_label\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def prepare_data(df):\n",
    "    df3 = df\n",
    "    df1 = pd.DataFrame(df.loc[:,[u'27',u'28',u'29',u'30',\n",
    "                                 u'31',u'32',u'33',u'34',\n",
    "                                 u'35',u'36',u'37',u'38',\n",
    "                                 u'39',u'40',u'41',u'42',\n",
    "                                 u'43',u'44',u'45',u'46',\n",
    "                                 u'47',u'48',u'49',u'50',\n",
    "                                 u'51',u'52',u'53',u'54',\n",
    "                                 u'55']])\n",
    "    #0 , 26 8, 5 , 14, 23 , 58 -> boss\n",
    "    #17, 56, 16,9,, 25, 57 -> yes\n",
    "    #20, 18, 7 -> no\n",
    "    #df2 = pd.DataFrame(df.loc[:,[u'18',u'20',u'23',u'25',u'26']])\n",
    "    df2 = pd.DataFrame(df.drop([u'27',u'28',u'29',u'30',\n",
    "                                 u'31',u'32',u'33',u'34',\n",
    "                                 u'35',u'36',u'37',u'38',\n",
    "                                 u'39',u'40',u'41',u'42',\n",
    "                                 u'43',u'44',u'45',u'46',\n",
    "                                 u'47',u'48',u'49',u'50',\n",
    "                                 u'51',u'52',u'53',u'54',\n",
    "                                 u'55'],axis=1))\n",
    "    \n",
    "    return df1, df2, df3\n",
    "\n",
    "def encode(dataset):\n",
    "    drop_cols = []\n",
    "    for i in dataset.columns:\n",
    "        if isinstance(dataset[i].values[0], basestring):\n",
    "            drop_cols = drop_cols + [i]\n",
    "    \n",
    "    return encode_label(dataset, drop_cols)\n",
    "\n",
    "def encode_with_test(train, test):\n",
    "    agg_data = pd.concat([train, test],axis=0,ignore_index=True)\n",
    "    agg_data= encode(agg_data)\n",
    "    \n",
    "    return agg_data._slice(slice(0,train.shape[0]),axis=0), agg_data._slice(slice(train.shape[0],agg_data.shape[0]),axis=0)\n",
    "\n",
    "train = pd.read_csv('data.csv')\n",
    "label = train['label']\n",
    "train = train.drop('label',1)\n",
    "print len(train.columns)\n",
    "X_quiz = pd.read_csv('quiz.csv')\n",
    "\n",
    "#split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label)\n",
    "train_1, train_2, train_all = prepare_data(X_train)\n",
    "test_1, test_2, test_all = prepare_data(X_test)\n",
    "quiz_1, quiz_2, quiz_all = prepare_data(X_quiz)\n",
    "                             \n",
    "#agg_data = pd.concat([train, X_quiz],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "#display(agg_data.shape[0])\n",
    "#train = agg_data._slice(slice(0,train.shape[0]),0)\n",
    "#X_quiz = agg_data._slice(slice(train.shape[0],agg_data.shape[0]),0)\n",
    "#pca = PCA(n_components=100)\n",
    "#train = pca.fit(train).transform(train)\n",
    "#display(train.shape)\n",
    "#display(X_quiz.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1467517757395.23, NNZs: 656, Bias: 38054393207.872116, T: 95127, Avg. loss: 33482005649986953781706752.000000\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 454458896110.02, NNZs: 656, Bias: 35316741513.391579, T: 190254, Avg. loss: 16741036980985491938607104.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 254753331693.49, NNZs: 656, Bias: 31027055955.842602, T: 285381, Avg. loss: 11160692567708656769957888.000000\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 172723752882.41, NNZs: 656, Bias: 28276253339.055355, T: 380508, Avg. loss: 8370519680838223697805312.000000\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 128995665865.17, NNZs: 656, Bias: 26103794675.211311, T: 475635, Avg. loss: 6696415831368971975655424.000000\n",
      "Total training time: 0.89 seconds.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-777be66db68d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtres1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtres2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtres3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtres4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_layer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-91-777be66db68d>\u001b[0m in \u001b[0;36mtrain_layer1\u001b[1;34m(train1, train2, train3, train4, test1, test2, test3, test4, train_label)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mtres2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madaboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mnew3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_layer1(train1, train2, train3, train4, test1, test2, test3, test4, train_label):\n",
    "    train1, test1 = encode_with_test(train1, test1)\n",
    "    train2, test2 = encode_with_test(train2, test2)\n",
    "    train3, test3 = encode_with_test(train3, test3)\n",
    "    train4, test4 = encode_with_test(train4, test4)\n",
    "    \n",
    "    #X_train1, X_test1, y_train1, y_test1 = train_test_split(train1, label)\n",
    "    #X_train2, X_test2, y_train2, y_test2 = train_test_split(train2, label)\n",
    "    #X_train3, X_test3, y_train3, y_test3 = train_test_split(train3, label)\n",
    "    \n",
    "    X_train1, y_train1 = train1, train_label\n",
    "    X_train2, y_train2 = train2, train_label\n",
    "    X_train3, y_train3 = train3, train_label\n",
    "    X_train4, y_train4 = train4, train_label\n",
    "    \n",
    "    xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "    sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\",shuffle=True,alpha=0.0001,epsilon=0.1, verbose=1)\n",
    "    gbc = GradientBoostingClassifier(loss='exponent',random_state=0,n_estimators=500,learning_rate=0.05,max_depth=7)\n",
    "    svm = SVC(kernel='linear', C=1.0)\n",
    "    \n",
    "    gbm.fit(X_train1, y_train1)\n",
    "    new1 = gbm.predict(X_train1)\n",
    "    tres1 = gbm.predict(test1)\n",
    "\n",
    "    adaboost = AdaBoostClassifier(n_estimators=300)\n",
    "    adaboost.fit(X_train2, y_train2)\n",
    "    new2 = adaboost.predict(X_train2)\n",
    "    tres2 = adaboost.predict(test2)\n",
    "    \n",
    "    sgd.fit(X_train3, y_train3)\n",
    "    new3 = sgd.predict(X_train3)\n",
    "    tres3 = sgd.predict(test3)\n",
    "\n",
    "    xtree.fit(X_train4, y_train4)\n",
    "    new4 = xtree.predict(X_train4)\n",
    "    tres4 = xtree.predict(test4)\n",
    "    \n",
    "    return np.column_stack((new1,new2,new3,new4)), np.column_stack((tres1,tres2,tres3,tres4))\n",
    "\n",
    "train, test = train_layer1(train_1,train_2,train_3, X_train, test_1, test_2, test_3, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-e44eb1e34a32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_layer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "def train_layer2(X_train, X_test, y_train, y_test):\n",
    "    xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "    xtree.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = xtree.predict(X_test)\n",
    "    print classification_report(y_test, predictions)\n",
    "    \n",
    "train_layer2(train, test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bleding train set and valid set...\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "            oob_score=False, random_state=398, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "            oob_score=False, random_state=1234, verbose=0,\n",
      "            warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "2 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "           oob_score=False, random_state=312, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "3 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "           oob_score=False, random_state=12, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "4 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "5 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.4, n_estimators=50, random_state=None)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "6 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.3, n_estimators=50, random_state=None)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "7 BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "         random_state=851, verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "         random_state=1556, verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "10 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Blending models by logistic regression...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.9362    0.9649    0.9504     13312\n",
      "          1     0.9536    0.9164    0.9346     10470\n",
      "\n",
      "avg / total     0.9439    0.9436    0.9434     23782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import blend_clf\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "\n",
    "\n",
    "#gbc = GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10)\n",
    "clfs = [RandomForestClassifier(n_estimators=1000, n_jobs=-1, criterion='gini', random_state=398),\n",
    "        RandomForestClassifier(n_estimators=1000, n_jobs=-1, criterion='entropy', random_state=1234),\n",
    "        ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, criterion='gini', max_features='sqrt', random_state=312),\n",
    "        ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, criterion='entropy', max_features='log2', random_state=12),\n",
    "        xgb.XGBClassifier(n_estimators=100,learning_rate=0.1,max_depth=7),\n",
    "        AdaBoostClassifier(n_estimators=50, learning_rate=0.4),\n",
    "        AdaBoostClassifier(n_estimators=50, learning_rate=0.3),\n",
    "        BaggingClassifier(DecisionTreeClassifier(), n_jobs=-1,random_state=851,n_estimators=100),\n",
    "        BaggingClassifier(DecisionTreeClassifier(), n_jobs=-1,random_state=1556,n_estimators=100),\n",
    "        DecisionTreeClassifier(criterion='entropy',splitter='best'),\n",
    "        KNeighborsClassifier(n_neighbors=3)]\n",
    "\n",
    "\n",
    "predictions = blend_clf(clfs, X_train1.as_matrix(),X_test1.as_matrix(),y_train1.as_matrix())\n",
    "print classification_report(y_test1, predictions,digits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SET 1 -- Tie to XTREE Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95127, 23)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.9274    0.9702    0.9483     13309\n",
      "          1     0.9597    0.9035    0.9307     10473\n",
      "\n",
      "avg / total     0.9416    0.9408    0.9406     23782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from classifier import train_xtree_classifer, train_rf, train_SGD_SVM, train_friedman_xgbm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_1 = encode(train_2)\n",
    "\n",
    "print(train_1.shape)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "xtree.fit(X_train1, y_train1)\n",
    "predictions = xtree.predict(X_test1)\n",
    "print classification_report(y_test1, predictions, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95127, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.8533    0.4103    0.5542      5274\n",
      "          1     0.5542    0.9122    0.6896      4239\n",
      "\n",
      "avg / total     0.7200    0.6340    0.6145      9513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from classifier import train_rf, train_gbc, train_bagging_decision_tree, train_xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "print train_1.shape\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train, test_size=0.1)\n",
    "\n",
    "sgd = SGDClassifier(loss=\"log\", penalty=\"l2\",shuffle=True,alpha=0.00001,epsilon=0.01, random_state = 123)\n",
    "gbc = GradientBoostingClassifier(loss='deviance',random_state=0,n_estimators=200,learning_rate=0.05,max_depth=7)\n",
    "svm = SVC(kernel='linear', C=0.3)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=1, random_state=123, max_features='sqrt')\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features=None,random_state=0)\n",
    "adaBoost = AdaBoostClassifier(n_estimators=200, learning_rate=0.4)\n",
    "gnb = BernoulliNB()\n",
    "dt = DecisionTreeClassifier(criterion='entropy',splitter='best')\n",
    "nn = KNeighborsClassifier(n_neighbors=3)\n",
    "xgb = XGBClassifier(learning_rate=0.3, max_depth=7, n_estimators=800)\n",
    "bxt =  AdaBoostClassifier(base_estimator=ExtraTreesClassifier(n_jobs=-1, n_estimators=10, min_samples_split=1,max_features=None, \n",
    "                                                                 random_state=2345), n_estimators=50, learning_rate=0.3)\n",
    "\n",
    "bag_sgd = BaggingClassifier(sgd, n_jobs=-1,random_state=851,n_estimators=50)\n",
    "\n",
    "ad_sgd = AdaBoostClassifier(base_estimator=sgd, n_estimators=50, learning_rate=0.1)\n",
    "votes = VotingClassifier([('bag',bag_sgd),('ad',ad_sgd)],voting='soft')\n",
    "\n",
    "rfecv = RFECV(estimator=sgd, step=1, cv=StratifiedKFold(y_train1, 2),\n",
    "              scoring='accuracy')\n",
    "\n",
    "clf = rfecv.fit(X_train1,y_train1)\n",
    "predictions = clf.predict(X_test1)\n",
    "print classification_report(y_test1, predictions, digits=4)\n",
    "\n",
    "\n",
    "#votes = VotingClassifier(estimators=[('sgd', sgd), ('gbc', gbc), ('svm', svm),('rf',rf),('ab',adaBoost)], voting='hard')\n",
    "#votes.fit(X_train1,y_train1)\n",
    "#predictions = votes.predict(X_test1)\n",
    "#print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cf3e1d1e384c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdropout_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     n_iter=100)\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;31m# Now train based on a problem transformed into regression.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             log.error(\"\\n{}{}{}\\n\\n{}\\n\".format(\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mis_best_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0mavg_train_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mavg_train_error\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_train_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sknn/backend/lasagne/mlp.pyc\u001b[0m in \u001b[0;36m_train_impl\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_valid_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sknn/backend/lasagne/mlp.pyc\u001b[0m in \u001b[0;36m_batch_impl\u001b[1;34m(self, X, y, w, processor, mode, output, shuffle)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sknn.mlp import Classifier, Layer\n",
    "from sknn.platform import gpu32, threads16\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_1 = encode(train_1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "\n",
    "X_train1 = X_train1.as_matrix()\n",
    "y_train1 = y_train1.as_matrix()\n",
    "X_test1 = X_test1.as_matrix()\n",
    "y_test1 = y_test1.as_matrix()\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Rectifier\", units=500),\n",
    "        Layer(\"Rectifier\", units=500),\n",
    "        Layer(\"Rectifier\", units=500),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    regularize='L2',\n",
    "    weight_decay=0.001,\n",
    "    dropout_rate=0.25,\n",
    "    n_iter=100)\n",
    "nn.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = nn.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95127, 5189)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.9252    0.9706    0.9473     13426\n",
      "          1     0.9593    0.8982    0.9277     10356\n",
      "\n",
      "avg / total     0.9400    0.9391    0.9388     23782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from classifier import train_xtree_classifer, train_rf, train_SGD_SVM, train_friedman_xgbm\n",
    "from sklearn.metrics import classification_report\n",
    "## XTREE is extremely effective to Set 1\n",
    "display(train_1.shape)\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "xtree.fit(X_train1, y_train1)\n",
    "predictions = xtree.predict(X_test1)\n",
    "print classification_report(y_test1, predictions, digits=4)\n",
    "\n",
    "#xtree_clf = train_xtree_classifer(X_train1,y_train1)\n",
    "#predictions = xtree_clf.predict(X_test1)\n",
    "#print classification_report(y_test1, predictions)\n",
    "\n",
    "#gbm_clf = train_friedman_xgbm(X_train1, y_train1)\n",
    "#predictions = gbm_clf.predict(X_test1)\n",
    "#print classification_report(y_test1, predictions)\n",
    "\n",
    "#rf_clf = train_rf(X_train1, y_train1)\n",
    "#predictions = rf_clf.predict(X_test1)\n",
    "#print classification_report(y_test1, predictions)\n",
    "\n",
    "#svm_clf = train_SGD_SVM(X_train1, y_train1)\n",
    "#predictions = svm_clf.predict(X_test1)\n",
    "#print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "3 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "4 GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
      "              max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              presort='auto', random_state=None, subsample=0.5, verbose=0,\n",
      "              warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "[-1  1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.93      0.97      0.95     13233\n",
      "          1       0.96      0.91      0.93     10549\n",
      "\n",
      "avg / total       0.94      0.94      0.94     23782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import blend\n",
    "\n",
    "predictions = blend(X_train1.as_matrix(),X_test1.as_matrix(),y_train1.as_matrix())\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.9275    0.9682    0.9474     13315\n",
      "          1     0.9572    0.9037    0.9297     10467\n",
      "\n",
      "avg / total     0.9406    0.9398    0.9396     23782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test1, predictions, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = (predictions - predictions.min()) / (predictions.max() - predictions.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
      " -1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      " -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.\n",
      " -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1.\n",
      "  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.\n",
      "  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.\n",
      " -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.\n",
      " -1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      "  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      "  1. -1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      " -1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1.  1.  1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1.\n",
      " -1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      " -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      " -1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1.\n",
      " -1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "  1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.\n",
      "  1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1.\n",
      " -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.\n",
      "  1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.\n",
      "  1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "predictions[predictions == 0] = -1\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.92      0.92      0.92     17819\n",
      "          1       0.90      0.90      0.90     13891\n",
      "\n",
      "avg / total       0.91      0.91      0.91     31710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_decision_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_1 = encode(train_1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, label)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='gini',max_depth=300).fit(X_train1, y_train1)\n",
    "predictions = dt_clf.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SET 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 18   20                     23   25                    26  \\\n",
      "32987       pro_pro  0_0             nsubj_root  f_g         query_w_align   \n",
      "39305       null_el  0_0       conj_and_prep_to  g_f           align_check   \n",
      "105098   indef_null  0_0              dobj_root  f_f   explain_acknowledge   \n",
      "56801       def_def  0_0         root_prep_from  f_g      query_yn_clarify   \n",
      "117899      pro_def  0_0           prep_of_dobj  f_g        check_query_yn   \n",
      "79556       def_def  0_0              dobj_root  f_g       explain_explain   \n",
      "97446      null_def  0_0              dobj_dobj  g_g        query_yn_align   \n",
      "79129      def_null  0_0           prep_of_dobj  g_g        align_query_yn   \n",
      "29308     indef_def  0_0             nsubj_pobj  f_f      explain_query_yn   \n",
      "12260       pro_def  0_0           root_prep_of  f_g           check_align   \n",
      "87136     def_indef  0_0  prep_below_prep_above  f_g        check_instruct   \n",
      "119149     null_def  0_0        prep_to_prep_at  g_g        align_instruct   \n",
      "55616     dctc_dctc  0_0       det_prep_towards  g_g      instruct_clarify   \n",
      "113599      def_def  0_0   prep_over_prep_above  f_g         check_explain   \n",
      "64517     indef_def  0_0             nsubj_dobj  g_g        check_query_yn   \n",
      "88383     indef_def  0_0          nsubj_prep_at  f_g         explain_align   \n",
      "102392       el_def  0_0        prep_over_nsubj  g_g     instruct_instruct   \n",
      "388         def_def  0_0                root_nn  g_g        align_query_yn   \n",
      "18398      def_null  0_0          dobj_npadvmod  g_f      instruct_explain   \n",
      "50934     indef_pro  0_0              dobj_root  f_g      query_yn_clarify   \n",
      "53952    indef_null  0_0       npadvmod_prep_of  f_g      explain_instruct   \n",
      "27391     indef_def  0_0           dobj_conj_or  g_f     query_yn_query_yn   \n",
      "109476    null_null  0_0           prep_of_dobj  g_g      explain_query_yn   \n",
      "118619      pro_pro  0_0        prep_from_nsubj  g_g       clarify_clarify   \n",
      "53520    dctc_indef  0_0            det_prep_of  g_f      explain_query_yn   \n",
      "105235      def_pro  0_0           prep_of_root  g_g     instruct_instruct   \n",
      "120312      def_def  0_0        prep_of_prep_at  g_g     instruct_query_yn   \n",
      "7959        def_pro  0_0     prep_at_prep_above  g_g      explain_instruct   \n",
      "69925       pro_def  0_0                pobj_nn  g_g         reply_w_align   \n",
      "106219      def_def  0_0           prep_to_dobj  g_g        check_query_yn   \n",
      "...             ...  ...                    ...  ...                   ...   \n",
      "85346     indef_def  0_0  ccomp_prep_underneath  g_f        query_yn_check   \n",
      "77491       def_def  0_0               nn_nsubj  f_g         check_explain   \n",
      "68950       def_def  0_0     conj_and_prep_with  f_g         explain_align   \n",
      "97924     indef_def  0_0          dep_prep_from  g_g      explain_instruct   \n",
      "10976       def_def  0_0           pobj_prep_at  g_g      clarify_instruct   \n",
      "51206     indef_pro  0_0                dobj_na  g_g      query_yn_clarify   \n",
      "48672     def_indef  0_0              root_dobj  g_g      explain_query_yn   \n",
      "55166      def_null  0_0         prep_from_dobj  g_g       explain_explain   \n",
      "13638       def_def  0_0             prep_of_nn  g_g      clarify_query_yn   \n",
      "101165      def_def  0_0     prep_of_prep_above  f_g      query_w_query_yn   \n",
      "102700    indef_def  0_0             dobj_nsubj  g_g       explain_explain   \n",
      "98512    null_indef  0_0           root_prep_of  g_g     query_yn_instruct   \n",
      "104826    indef_def  0_0              dobj_dobj  g_g     query_yn_query_yn   \n",
      "45804    null_indef  0_0             pobj_nsubj  f_f         explain_align   \n",
      "58630     def_indef  0_0             dobj_nsubj  g_f        instruct_align   \n",
      "111432     def_dctc  0_0       prep_above_rcmod  g_f         check_explain   \n",
      "38955       def_def  0_0        prep_of_prep_by  g_f         align_explain   \n",
      "68618       pro_def  0_0            nsubj_nsubj  f_f         query_w_check   \n",
      "90111     indef_def  0_0              dobj_dobj  g_g       explain_reply_w   \n",
      "20007      pro_null  0_0               det_dobj  g_g  acknowledge_query_yn   \n",
      "18058      null_def  0_0           pobj_prep_of  f_g      reply_w_instruct   \n",
      "16447      pro_null  0_0          prep_of_ccomp  f_g     query_yn_query_yn   \n",
      "63847      def_null  0_0        prep_to_prep_of  f_g        check_instruct   \n",
      "24928    indef_poss  0_0           dobj_prep_of  g_g     query_yn_instruct   \n",
      "23254     pro_indef  0_0           prep_of_dobj  g_g     instruct_query_yn   \n",
      "107040     null_def  0_0             dobj_ccomp  g_g      query_yn_explain   \n",
      "71792       def_def  0_0             prep_of_nn  g_g     instruct_query_yn   \n",
      "20405     indef_pro  0_0             dobj_nsubj  f_g       explain_explain   \n",
      "87531   numpro_null  0_0         prep_into_dobj  g_g     query_yn_query_yn   \n",
      "100669     dctc_def  0_0     prep_below_prep_at  g_g         reply_w_align   \n",
      "\n",
      "                         58  \n",
      "32987                    na  \n",
      "39305     prep_towards_root  \n",
      "105098                   na  \n",
      "56801                    na  \n",
      "117899           pobj_ccomp  \n",
      "79556                    na  \n",
      "97446            ccomp_root  \n",
      "79129         prep_at_ccomp  \n",
      "29308            ccomp_root  \n",
      "12260                    na  \n",
      "87136             root_root  \n",
      "119149           xcomp_root  \n",
      "55616   prep_above_conj_and  \n",
      "113599          rcmod_nsubj  \n",
      "64517            root_ccomp  \n",
      "88383            root_rcmod  \n",
      "102392            root_root  \n",
      "388                      na  \n",
      "18398          conj_and_dep  \n",
      "50934                    na  \n",
      "53952           dep_prep_to  \n",
      "27391            ccomp_dobj  \n",
      "109476           dobj_ccomp  \n",
      "118619           root_xcomp  \n",
      "53520       prep_below_root  \n",
      "105235                   na  \n",
      "120312         prep_at_root  \n",
      "7959              dep_xcomp  \n",
      "69925             root_dobj  \n",
      "106219           root_ccomp  \n",
      "...                     ...  \n",
      "85346           ccomp_ccomp  \n",
      "77491        prep_past_root  \n",
      "68950      pobj_prepc_about  \n",
      "97924             dobj_root  \n",
      "10976             root_root  \n",
      "51206                    na  \n",
      "48672                    na  \n",
      "55166       prep_about_root  \n",
      "13638            nsubj_dobj  \n",
      "101165            root_dobj  \n",
      "102700            root_root  \n",
      "98512                    na  \n",
      "104826          ccomp_ccomp  \n",
      "45804             root_root  \n",
      "58630            xcomp_root  \n",
      "111432       root_prep_from  \n",
      "38955           pobj_advmod  \n",
      "68618              root_dep  \n",
      "90111           ccomp_xcomp  \n",
      "20007            root_ccomp  \n",
      "18058           dep_prep_of  \n",
      "16447         prep_to_ccomp  \n",
      "63847          root_prep_to  \n",
      "24928         ccomp_prep_at  \n",
      "23254         prep_at_ccomp  \n",
      "107040          ccomp_rcmod  \n",
      "71792             dobj_dobj  \n",
      "20405             root_root  \n",
      "87531           nsubj_ccomp  \n",
      "100669         root_prep_at  \n",
      "\n",
      "[750 rows x 6 columns]\n",
      "(750, 6)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-73176600d71a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m##XTREE is not very effective on set 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtrain_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mxtrain_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mxtrain_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/Kaggle_CMOS4771/classifier.py\u001b[0m in \u001b[0;36mtransform_corpus\u001b[1;34m(train)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1333\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1334\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 238\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from classifier import train_xtree_classifer, train_rf, train_SGD_SVM, train_friedman_xgbm, transform_corpus\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "##XTREE is not very effective on set 2\n",
    "print train_2\n",
    "xtrain_2 = transform_corpus(train_2)\n",
    "print xtrain_2.shape\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(xtrain_2, label)\n",
    "\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "xtree.fit(X_train2, y_train2)\n",
    "predictions = xtree.predict(X_test2)\n",
    "print classification_report(y_test2, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN SET 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-74:\n",
      "Process PoolWorker-78:\n",
      "Process PoolWorker-76:\n",
      "Process PoolWorker-80:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-77:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process PoolWorker-79:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-426c8908b9c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdt_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ada_boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/Kaggle_CMOS4771/classifier.py\u001b[0m in \u001b[0;36mtrain_ada_boost\u001b[1;34m(train_data, train_label)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'clf__n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_ada_boost\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_3 = encode(train_3)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(train_3, y_train)\n",
    "\n",
    "dt_clf = train_ada_boost(X_train3,y_train3)\n",
    "predictions = dt_clf.predict(X_test3)\n",
    "print classification_report(y_test3, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 36)\n",
      "(50000,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.83      0.79      5229\n",
      "          1       0.75      0.66      0.70      4146\n",
      "\n",
      "avg / total       0.75      0.75      0.75      9375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print train_3.shape\n",
    "print label.shape\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(train_3, y_train)\n",
    "\n",
    "\n",
    "rbf_svm = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "                max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                tol=0.001, verbose=False).fit(X_train3, y_train3)\n",
    "predictions = rbf_svm.predict(X_test3)\n",
    "print classification_report(y_test3, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.84      0.82      0.83      5229\n",
      "          1       0.78      0.80      0.79      4146\n",
      "\n",
      "avg / total       0.81      0.81      0.81      9375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from classifier import train_xtree_classifer, train_rf, train_SGD_SVM, train_friedman_xgbm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# XTree is okay in set 3\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "xtree.fit(X_train3, y_train3)\n",
    "predictions = xtree.predict(X_test3)\n",
    "print classification_report(y_test3, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.81      0.78      5229\n",
      "          1       0.74      0.66      0.70      4146\n",
      "\n",
      "avg / total       0.75      0.75      0.74      9375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, \n",
    "                                 subsample=1.0, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, init=None, random_state=None, \n",
    "                                 max_features='log2', verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "gbc.fit(X_train3, y_train3)\n",
    "predictions = gbc.predict(X_test3)\n",
    "print classification_report(y_test3, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from classifier import train_svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#svm_clf = train_svm(X_train3, y_train3)\n",
    "svm_clf = SVC(kernel='rbf', C=1.0, verbose=1).fit(X_train3, y_train3)\n",
    "predictions = svm_clf.predict(X_test3)\n",
    "print classification_report(y_test3, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 21.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.931\n",
      "Best parameters set:\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_friedman_xgbm\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "gbm_clf = xgb.XGBClassifier(n_estimators=500,learning_rate=0.1,max_depth=7)\n",
    "gbm_clf = train_friedman_xgbm(X_train, y_train)\n",
    "predictions = gbm_clf.predict(X_test)\n",
    "\n",
    "print classification_report(y_test, predictions)\n",
    "prediction = gbm_clf.predict(X_quiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_gbc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gbm_clf = train_gbc(X_train, y_train)\n",
    "predictions = gbm_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)\n",
    "\n",
    "gbm_clf = gbm_clf.fit(train, label)\n",
    "predictions = gbm_clf.predict(X_quiz)\n",
    "write_out(prediction,\"etc.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95127, 5932)\n",
      "-- Epoch 1\n",
      "Norm: 1183.99, NNZs: 4435, Bias: -1410.081057, T: 95127, Avg. loss: 3265.917802\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 907.37, NNZs: 4897, Bias: -1333.207342, T: 190254, Avg. loss: 1814.790041\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 766.81, NNZs: 5053, Bias: -1290.249714, T: 285381, Avg. loss: 1274.599461\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 683.67, NNZs: 5115, Bias: -1259.251816, T: 380508, Avg. loss: 988.901747\n",
      "Total training time: 4.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 628.24, NNZs: 5145, Bias: -1234.630124, T: 475635, Avg. loss: 811.077863\n",
      "Total training time: 5.19 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.89      0.84      0.86     17796\n",
      "          1       0.81      0.86      0.84     13914\n",
      "\n",
      "avg / total       0.85      0.85      0.85     31710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "\n",
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from classifier import voting\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sgd_clf = SGDClassifier(loss=\"log\", penalty=\"l2\",n_jobs=-1,shuffle=True,alpha=0.0001,epsilon=0.1, verbose=1)\n",
    "et_clf = ExtraTreesClassifier(n_jobs=-1,n_estimators=300,max_depth=None,max_features='sqrt',min_samples_split=1)\n",
    "\n",
    "votes = voting(X_train,y_train,sgd_clf,et_clf)\n",
    "\n",
    "predictions = votes.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a6fd35dae8f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "\n",
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "#hinge -> 84 %\n",
    "#logisitc regression -> 53&\n",
    "from classifier import train_SGD_SVM\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svm_clf = train_SGD_SVM(X_train, y_train)\n",
    "predictions = svm_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)\n",
    "prediction = svm_clf.predict(X_quiz)\n",
    "write_out(prediction,\"sgd.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 966.76, NNZs: 50, Bias: 58.190747, T: 95127, Avg. loss: 3151.446006\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Norm: 952.95, NNZs: 50, Bias: 26.780075, T: 95127, Avg. loss: 3155.752894\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 733.83, NNZs: 50, Bias: -19.324825, T: 190254, Avg. loss: 1764.847206\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Norm: 730.51, NNZs: 50, Bias: -30.762732, T: 190254, Avg. loss: 1770.592779\n",
      "-- Epoch 1\n",
      "Norm: 620.66, NNZs: 50, Bias: -29.826759, T: 285381, Avg. loss: 1248.568796\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.48 seconds.\n",
      "Norm: 957.99, NNZs: 50, Bias: -3.919158, T: 95127, Avg. loss: 3095.806939\n",
      "-- Epoch 4\n",
      "Total training time: 0.17 seconds.\n",
      "Norm: 964.91, NNZs: 50, Bias: 12.917304, T: 95127, Avg. loss: 3168.758487\n",
      "Total training time: 0.12 seconds.\n",
      "Norm: 619.35, NNZs: 50, Bias: -30.056329, T: 285381, Avg. loss: 1254.145893\n",
      "-- Epoch 2\n",
      "-- Epoch 2\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 544.48, NNZs: 50, Bias: -30.063568, T: 380508, Avg. loss: 973.254199\n",
      "Norm: 735.68, NNZs: 50, Bias: -32.505516, T: 190254, Avg. loss: 1770.041339\n",
      "Total training time: 0.69 seconds.\n",
      "Norm: 746.13, NNZs: 50, Bias: -23.286132, T: 190254, Avg. loss: 1741.394221\n",
      "-- Epoch 5\n",
      "Total training time: 0.26 seconds.\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Norm: 545.83, NNZs: 50, Bias: -27.358920, T: 380508, Avg. loss: 978.129034\n",
      "Norm: 487.68, NNZs: 50, Bias: -27.035600, T: 475635, Avg. loss: 800.846472\n",
      "Norm: 632.46, NNZs: 50, Bias: -28.603851, T: 285381, Avg. loss: 1230.260533\n",
      "Total training time: 0.82 seconds.\n",
      "Total training time: 0.71 seconds.\n",
      "Norm: 627.05, NNZs: 50, Bias: -30.742019, T: 285381, Avg. loss: 1251.811027\n",
      "-- Epoch 5\n",
      "Total training time: 0.49 seconds.\n",
      "Total training time: 0.43 seconds.\n",
      "Norm: 982.85, NNZs: 50, Bias: 47.262192, T: 95127, Avg. loss: 3205.784181\n",
      "-- Epoch 4\n",
      "-- Epoch 4\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Norm: 489.78, NNZs: 50, Bias: -28.389794, T: 475635, Avg. loss: 805.725623\n",
      "Total training time: 0.91 seconds.\n",
      "Norm: 980.52, NNZs: 50, Bias: 11.151077, T: 95127, Avg. loss: 3105.775610\n",
      "Norm: 549.14, NNZs: 50, Bias: -29.859978, T: 380508, Avg. loss: 958.812350\n",
      "Total training time: 0.16 seconds.\n",
      "Norm: 750.95, NNZs: 50, Bias: -29.636462, T: 190254, Avg. loss: 1797.256445\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 543.83, NNZs: 50, Bias: -28.195952, T: 380508, Avg. loss: 975.714340\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 492.66, NNZs: 50, Bias: -26.576011, T: 475635, Avg. loss: 789.138158\n",
      "Norm: 751.84, NNZs: 50, Bias: -30.767139, T: 190254, Avg. loss: 1743.065624\n",
      "Total training time: 0.93 seconds.\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 632.86, NNZs: 50, Bias: -27.407237, T: 285381, Avg. loss: 1272.188916\n",
      "-- Epoch 3\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 980.15, NNZs: 50, Bias: 20.167992, T: 95127, Avg. loss: 3112.263051\n",
      "Total training time: 0.22 seconds.\n",
      "Norm: 960.91, NNZs: 50, Bias: -2.014294, T: 95127, Avg. loss: 3296.642233\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Norm: 481.55, NNZs: 50, Bias: -27.154732, T: 475635, Avg. loss: 801.496498\n",
      "-- Epoch 2\n",
      "Total training time: 1.00 seconds.\n",
      "Norm: 979.50, NNZs: 50, Bias: -10.547521, T: 95127, Avg. loss: 2956.740789\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 632.88, NNZs: 50, Bias: -40.329168, T: 285381, Avg. loss: 1231.762769\n",
      "Total training time: 0.65 seconds.\n",
      "Norm: 740.89, NNZs: 50, Bias: -17.238612, T: 190254, Avg. loss: 1748.036430\n",
      "Norm: 554.50, NNZs: 50, Bias: -25.266698, T: 380508, Avg. loss: 990.865257\n",
      "-- Epoch 4\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 758.79, NNZs: 50, Bias: -26.280386, T: 190254, Avg. loss: 1671.458005\n",
      "Norm: 737.48, NNZs: 50, Bias: -31.334522, T: 190254, Avg. loss: 1843.642586\n",
      "-- Epoch 1\n",
      "Total training time: 0.42 seconds.\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 3\n",
      "Norm: 499.40, NNZs: 50, Bias: -24.174105, T: 475635, Avg. loss: 815.104979\n",
      "Norm: 554.60, NNZs: 50, Bias: -27.327875, T: 380508, Avg. loss: 961.684595\n",
      "Total training time: 1.06 seconds.\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 5\n",
      "Norm: 617.38, NNZs: 50, Bias: -36.166869, T: 285381, Avg. loss: 1299.942831\n",
      "Norm: 954.61, NNZs: 50, Bias: 35.568810, T: 95127, Avg. loss: 3370.088487\n",
      "Norm: 635.51, NNZs: 50, Bias: -28.314254, T: 285381, Avg. loss: 1186.375364\n",
      "Norm: 620.59, NNZs: 50, Bias: -26.650298, T: 285381, Avg. loss: 1236.374220\n",
      "Total training time: 0.26 seconds.\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.74 seconds.\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "Norm: 975.98, NNZs: 50, Bias: 119.239719, T: 95127, Avg. loss: 3335.554107\n",
      "Norm: 981.86, NNZs: 50, Bias: 79.758257, T: 95127, Avg. loss: 3219.349877\n",
      "-- Epoch 4\n",
      "Total training time: 0.19 seconds.\n",
      "Norm: 962.41, NNZs: 50, Bias: 22.637794, T: 95127, Avg. loss: 3265.026010\n",
      "-- Epoch 2\n",
      "Total training time: 0.16 seconds.\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 2\n",
      "Norm: 738.54, NNZs: 50, Bias: -17.892299, T: 190254, Avg. loss: 1883.464957\n",
      "Norm: 539.48, NNZs: 50, Bias: -35.346223, T: 380508, Avg. loss: 1010.870005\n",
      "Total training time: 0.85 seconds.\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "Norm: 495.30, NNZs: 50, Bias: -28.766942, T: 475635, Avg. loss: 791.306675\n",
      "Total training time: 1.24 seconds.\n",
      "Norm: 554.05, NNZs: 50, Bias: -22.589227, T: 380508, Avg. loss: 926.060493\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 543.10, NNZs: 50, Bias: -22.751802, T: 380508, Avg. loss: 963.254190\n",
      "Norm: 747.03, NNZs: 50, Bias: -17.958543, T: 190254, Avg. loss: 1800.704225\n",
      "-- Epoch 5\n",
      "Total training time: 1.02 seconds.\n",
      "Norm: 751.85, NNZs: 50, Bias: 3.179753, T: 190254, Avg. loss: 1860.110527\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.42 seconds.\n",
      "Norm: 484.51, NNZs: 50, Bias: -29.866398, T: 475635, Avg. loss: 830.437504\n",
      "-- Epoch 3\n",
      "-- Epoch 3\n",
      "Total training time: 1.04 seconds.\n",
      "Norm: 744.42, NNZs: 50, Bias: -19.595026, T: 190254, Avg. loss: 1827.207945\n",
      "Norm: 617.42, NNZs: 50, Bias: -34.866527, T: 285381, Avg. loss: 1325.289388\n",
      "Norm: 984.82, NNZs: 50, Bias: 1.489836, T: 95127, Avg. loss: 3261.951253\n",
      "Total training time: 0.53 seconds.\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 1\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "Norm: 487.42, NNZs: 50, Bias: -24.113767, T: 475635, Avg. loss: 792.472469\n",
      "Norm: 496.96, NNZs: 50, Bias: -21.076669, T: 475635, Avg. loss: 763.292894\n",
      "-- Epoch 4\n",
      "Total training time: 1.04 seconds.\n",
      "Norm: 624.04, NNZs: 50, Bias: -19.410024, T: 285381, Avg. loss: 1308.342188\n",
      "Total training time: 1.25 seconds.\n",
      "Norm: 629.66, NNZs: 50, Bias: -26.191504, T: 285381, Avg. loss: 1272.441315\n",
      "Total training time: 0.67 seconds.\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 758.54, NNZs: 50, Bias: -27.777218, T: 190254, Avg. loss: 1822.936763\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "-- Epoch 3\n",
      "Norm: 974.66, NNZs: 50, Bias: 23.281591, T: 95127, Avg. loss: 2988.612698\n",
      "Norm: 544.82, NNZs: 50, Bias: -22.432148, T: 380508, Avg. loss: 1032.059550\n",
      "Total training time: 0.28 seconds.\n",
      "Norm: 624.90, NNZs: 50, Bias: -28.226365, T: 285381, Avg. loss: 1288.309042\n",
      "-- Epoch 2\n",
      "Norm: 543.89, NNZs: 50, Bias: -25.010298, T: 380508, Avg. loss: 1016.698269\n",
      "Total training time: 0.85 seconds.\n",
      "Total training time: 1.01 seconds.\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 4\n",
      "Norm: 548.74, NNZs: 50, Bias: -28.411108, T: 380508, Avg. loss: 990.062850\n",
      "-- Epoch 5\n",
      "Norm: 635.84, NNZs: 50, Bias: -32.384456, T: 285381, Avg. loss: 1288.007936\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 743.62, NNZs: 50, Bias: -35.143249, T: 190254, Avg. loss: 1687.689964\n",
      "Norm: 955.53, NNZs: 50, Bias: 53.551793, T: 95127, Avg. loss: 3114.036684\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 489.50, NNZs: 50, Bias: -21.272190, T: 475635, Avg. loss: 848.757127\n",
      "Total training time: 0.49 seconds.\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 1\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 3\n",
      "Norm: 489.40, NNZs: 50, Bias: -19.786581, T: 475635, Avg. loss: 835.631536\n",
      "-- Epoch 1\n",
      "Norm: 549.06, NNZs: 50, Bias: -31.659000, T: 380508, Avg. loss: 1002.941952\n",
      "Total training time: 1.13 seconds.\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 551.43, NNZs: 50, Bias: -35.434135, T: 380508, Avg. loss: 1002.209069\n",
      "Norm: 491.24, NNZs: 50, Bias: -26.787095, T: 475635, Avg. loss: 813.397013\n",
      "Total training time: 1.24 seconds.\n",
      "Norm: 976.21, NNZs: 50, Bias: 10.372910, T: 95127, Avg. loss: 3062.392480\n",
      "Total training time: 0.93 seconds.\n",
      "Norm: 970.78, NNZs: 50, Bias: 35.916867, T: 95127, Avg. loss: 3052.376524\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 960.23, NNZs: 50, Bias: 25.617711, T: 95127, Avg. loss: 3174.320367\n",
      "Norm: 732.28, NNZs: 50, Bias: -9.953347, T: 190254, Avg. loss: 1743.220080\n",
      "-- Epoch 2\n",
      "Total training time: 0.61 seconds.\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Norm: 951.11, NNZs: 50, Bias: 8.026393, T: 95127, Avg. loss: 2972.138258\n",
      "Norm: 625.16, NNZs: 50, Bias: -32.836095, T: 285381, Avg. loss: 1198.708882\n",
      "Total training time: 0.25 seconds.\n",
      "Norm: 494.10, NNZs: 50, Bias: -28.707348, T: 475635, Avg. loss: 823.894501\n",
      "-- Epoch 2\n",
      "Norm: 493.29, NNZs: 50, Bias: -27.517324, T: 475635, Avg. loss: 824.134852\n",
      "Total training time: 1.44 seconds.\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 745.34, NNZs: 50, Bias: -21.180512, T: 190254, Avg. loss: 1721.127348\n",
      "-- Epoch 1\n",
      "Total training time: 0.51 seconds.\n",
      "Total training time: 1.22 seconds.\n",
      "Norm: 755.41, NNZs: 50, Bias: -7.447432, T: 190254, Avg. loss: 1730.979349\n",
      "-- Epoch 3\n",
      "Norm: 617.50, NNZs: 50, Bias: -31.336200, T: 285381, Avg. loss: 1234.081751\n",
      "Total training time: 0.53 seconds.\n",
      "Norm: 978.94, NNZs: 50, Bias: 33.684129, T: 95127, Avg. loss: 3305.298774\n",
      "Norm: 733.70, NNZs: 50, Bias: -39.886489, T: 190254, Avg. loss: 1772.487743\n",
      "Total training time: 0.87 seconds.\n",
      "Norm: 748.94, NNZs: 50, Bias: -33.670485, T: 190254, Avg. loss: 1673.335847\n",
      "Total training time: 0.27 seconds.\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 2\n",
      "-- Epoch 3\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 3\n",
      "Norm: 546.26, NNZs: 50, Bias: -30.697814, T: 380508, Avg. loss: 937.534749\n",
      "Total training time: 1.17 seconds.\n",
      "Norm: 974.10, NNZs: 50, Bias: 70.369734, T: 95127, Avg. loss: 3135.115349\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 627.60, NNZs: 50, Bias: -25.874018, T: 285381, Avg. loss: 1218.555565\n",
      "-- Epoch 1\n",
      "Norm: 754.71, NNZs: 50, Bias: -17.350654, T: 190254, Avg. loss: 1845.458849\n",
      "Total training time: 0.83 seconds.\n",
      "Total training time: 0.53 seconds.\n",
      "Norm: 627.75, NNZs: 50, Bias: -32.625556, T: 285381, Avg. loss: 1255.856837\n",
      "Norm: 543.46, NNZs: 50, Bias: -28.092950, T: 380508, Avg. loss: 961.845919\n",
      "Norm: 627.57, NNZs: 50, Bias: -21.943650, T: 285381, Avg. loss: 1228.118076\n",
      "Total training time: 0.86 seconds.\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.86 seconds.\n",
      "Norm: 975.70, NNZs: 50, Bias: 83.625172, T: 95127, Avg. loss: 3278.593409\n",
      "-- Epoch 5\n",
      "-- Epoch 4\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 623.78, NNZs: 50, Bias: -38.198488, T: 285381, Avg. loss: 1186.013559\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 487.66, NNZs: 50, Bias: -26.396482, T: 475635, Avg. loss: 772.202434\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "Total training time: 1.41 seconds.\n",
      "Norm: 743.88, NNZs: 50, Bias: -10.634350, T: 190254, Avg. loss: 1767.331121\n",
      "-- Epoch 1\n",
      "Total training time: 0.63 seconds.\n",
      "Norm: 490.26, NNZs: 50, Bias: -23.846262, T: 475635, Avg. loss: 791.938515\n",
      "Norm: 626.11, NNZs: 50, Bias: -26.890317, T: 285381, Avg. loss: 1301.920786\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 4\n",
      "Norm: 740.56, NNZs: 50, Bias: -14.844657, T: 190254, Avg. loss: 1830.453741\n",
      "Norm: 943.75, NNZs: 50, Bias: 6.174988, T: 95127, Avg. loss: 3007.976803\n",
      "Norm: 548.96, NNZs: 50, Bias: -31.301037, T: 380508, Avg. loss: 925.704898\n",
      "Total training time: 0.34 seconds.\n",
      "Total training time: 1.39 seconds.\n",
      "Norm: 547.95, NNZs: 50, Bias: -27.027499, T: 380508, Avg. loss: 958.494851\n",
      "Total training time: 1.02 seconds.\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 548.03, NNZs: 50, Bias: -25.809416, T: 380508, Avg. loss: 950.705392\n",
      "Norm: 547.52, NNZs: 50, Bias: -32.332919, T: 380508, Avg. loss: 978.516302\n",
      "Total training time: 1.23 seconds.\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 967.48, NNZs: 50, Bias: -6.563176, T: 95127, Avg. loss: 3012.229112\n",
      "-- Epoch 5\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 966.39, NNZs: 50, Bias: 26.753866, T: 95127, Avg. loss: 3039.584070\n",
      "-- Epoch 1\n",
      "Norm: 628.19, NNZs: 50, Bias: -24.790830, T: 285381, Avg. loss: 1249.524624\n",
      "Norm: 547.42, NNZs: 50, Bias: -31.656901, T: 380508, Avg. loss: 1012.409644\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 1\n",
      "Total training time: 1.04 seconds.\n",
      "Norm: 622.64, NNZs: 50, Bias: -25.870496, T: 285381, Avg. loss: 1291.672443\n",
      "Norm: 723.02, NNZs: 50, Bias: -19.332237, T: 190254, Avg. loss: 1688.706263\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Total training time: 0.31 seconds.\n",
      "Norm: 490.25, NNZs: 50, Bias: -24.291266, T: 475635, Avg. loss: 762.530020\n",
      "Norm: 959.81, NNZs: 50, Bias: 29.267146, T: 95127, Avg. loss: 3140.426730\n",
      "Total training time: 1.28 seconds.\n",
      "Norm: 488.34, NNZs: 50, Bias: -23.190947, T: 475635, Avg. loss: 789.079021\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.22 seconds.\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "Total training time: 1.42 seconds.\n",
      "Norm: 752.90, NNZs: 50, Bias: -23.349631, T: 190254, Avg. loss: 1700.833074\n",
      "Total training time: 0.56 seconds.\n",
      "Norm: 493.59, NNZs: 50, Bias: -25.284586, T: 475635, Avg. loss: 783.128459\n",
      "-- Epoch 3\n",
      "Total training time: 1.57 seconds.\n",
      "Norm: 491.85, NNZs: 50, Bias: -28.593064, T: 475635, Avg. loss: 805.443198\n",
      "Norm: 961.50, NNZs: 50, Bias: 28.699680, T: 95127, Avg. loss: 3133.019923\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Total training time: 1.58 seconds.\n",
      "Norm: 980.69, NNZs: 50, Bias: -20.018352, T: 95127, Avg. loss: 3111.332815\n",
      "Norm: 493.06, NNZs: 50, Bias: -24.290862, T: 475635, Avg. loss: 832.350895\n",
      "Total training time: 1.32 seconds.\n",
      "Norm: 739.56, NNZs: 50, Bias: -14.077277, T: 190254, Avg. loss: 1712.424284\n",
      "Norm: 605.41, NNZs: 50, Bias: -25.292140, T: 285381, Avg. loss: 1195.074218\n",
      "Total training time: 0.86 seconds.\n",
      "Norm: 548.54, NNZs: 50, Bias: -28.375801, T: 380508, Avg. loss: 973.919510\n",
      "Total training time: 0.32 seconds.\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Norm: 738.89, NNZs: 50, Bias: -26.665021, T: 190254, Avg. loss: 1756.978337\n",
      "Norm: 548.38, NNZs: 50, Bias: -26.172903, T: 380508, Avg. loss: 1006.957388\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "Norm: 628.50, NNZs: 50, Bias: -31.572429, T: 285381, Avg. loss: 1203.811458\n",
      "Total training time: 0.90 seconds.\n",
      "Norm: 972.65, NNZs: 50, Bias: 42.551931, T: 95127, Avg. loss: 2948.248501\n",
      "Norm: 735.21, NNZs: 50, Bias: -26.491525, T: 190254, Avg. loss: 1760.798027\n",
      "-- Epoch 4\n",
      "Norm: 533.36, NNZs: 50, Bias: -25.743045, T: 380508, Avg. loss: 931.933213\n",
      "Total training time: 0.33 seconds.\n",
      "Total training time: 1.12 seconds.\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Norm: 616.95, NNZs: 50, Bias: -33.285039, T: 285381, Avg. loss: 1211.529998\n",
      "Norm: 495.49, NNZs: 50, Bias: -24.676880, T: 475635, Avg. loss: 801.626649\n",
      "Norm: 751.37, NNZs: 50, Bias: -31.547380, T: 190254, Avg. loss: 1753.020659\n",
      "-- Epoch 3\n",
      "Total training time: 0.63 seconds.\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Total training time: 1.56 seconds.\n",
      "Norm: 494.44, NNZs: 50, Bias: -21.363293, T: 475635, Avg. loss: 829.034744\n",
      "Norm: 621.14, NNZs: 50, Bias: -31.147891, T: 285381, Avg. loss: 1239.380002\n",
      "Total training time: 0.81 seconds.\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 4\n",
      "Norm: 968.64, NNZs: 50, Bias: 15.542500, T: 95127, Avg. loss: 3233.007498\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 552.07, NNZs: 50, Bias: -25.640811, T: 380508, Avg. loss: 940.031237\n",
      "Norm: 621.59, NNZs: 50, Bias: -26.208681, T: 285381, Avg. loss: 1245.140903\n",
      "Norm: 480.46, NNZs: 50, Bias: -25.861654, T: 475635, Avg. loss: 767.776044\n",
      "Total training time: 1.21 seconds.\n",
      "Norm: 747.18, NNZs: 50, Bias: -13.708835, T: 190254, Avg. loss: 1665.091608\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 544.45, NNZs: 50, Bias: -28.341012, T: 380508, Avg. loss: 966.665231\n",
      "-- Epoch 3\n",
      "Norm: 967.37, NNZs: 50, Bias: 41.207892, T: 95127, Avg. loss: 2940.752392\n",
      "Total training time: 1.08 seconds.\n",
      "Total training time: 0.33 seconds.\n",
      "Norm: 545.83, NNZs: 50, Bias: -28.918022, T: 380508, Avg. loss: 946.881796\n",
      "Norm: 629.91, NNZs: 50, Bias: -30.164043, T: 285381, Avg. loss: 1240.391552\n",
      "Total training time: 0.97 seconds.\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 5\n",
      "-- Epoch 5\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 751.85, NNZs: 50, Bias: -28.778823, T: 190254, Avg. loss: 1808.185964\n",
      "Norm: 542.69, NNZs: 50, Bias: -26.744000, T: 380508, Avg. loss: 971.121475\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 625.75, NNZs: 50, Bias: -22.934071, T: 285381, Avg. loss: 1181.286120\n",
      "-- Epoch 3\n",
      "Norm: 493.76, NNZs: 50, Bias: -24.519731, T: 475635, Avg. loss: 773.690246\n",
      "Total training time: 0.89 seconds.\n",
      "Norm: 1000.15, NNZs: 50, Bias: 38.426774, T: 95127, Avg. loss: 3363.352752\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.18 seconds.\n",
      "Total training time: 0.29 seconds.\n",
      "Norm: 489.57, NNZs: 50, Bias: -24.550527, T: 475635, Avg. loss: 795.584357\n",
      "Norm: 957.87, NNZs: 50, Bias: -7.591175, T: 95127, Avg. loss: 2918.870392\n",
      "-- Epoch 2\n",
      "Norm: 740.23, NNZs: 50, Bias: -26.754571, T: 190254, Avg. loss: 1655.605468\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 552.23, NNZs: 50, Bias: -25.377928, T: 380508, Avg. loss: 967.388453\n",
      "Norm: 488.53, NNZs: 50, Bias: -25.971818, T: 475635, Avg. loss: 779.508451\n",
      "-- Epoch 2\n",
      "Total training time: 0.61 seconds.\n",
      "Total training time: 1.42 seconds.\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 968.83, NNZs: 50, Bias: 12.091515, T: 95127, Avg. loss: 3209.279264\n",
      "Total training time: 1.30 seconds.\n",
      "Total training time: 0.28 seconds.\n",
      "Norm: 986.43, NNZs: 50, Bias: 17.642652, T: 95127, Avg. loss: 3187.519671\n",
      "Norm: 972.17, NNZs: 50, Bias: 36.102008, T: 95127, Avg. loss: 3242.538825\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 547.00, NNZs: 50, Bias: -20.655981, T: 380508, Avg. loss: 922.017555\n",
      "Norm: 625.94, NNZs: 50, Bias: -38.009521, T: 285381, Avg. loss: 1276.568249\n",
      "-- Epoch 2\n",
      "Total training time: 0.28 seconds.\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 486.23, NNZs: 50, Bias: -25.852967, T: 475635, Avg. loss: 798.940361\n",
      "Norm: 764.81, NNZs: 50, Bias: -12.884206, T: 190254, Avg. loss: 1879.845814\n",
      "Norm: 746.87, NNZs: 50, Bias: -22.492273, T: 190254, Avg. loss: 1798.582981\n",
      "-- Epoch 4\n",
      "Total training time: 1.50 seconds.\n",
      "Total training time: 0.62 seconds.\n",
      "Norm: 622.91, NNZs: 50, Bias: -28.399041, T: 285381, Avg. loss: 1174.796189\n",
      "Total training time: 0.49 seconds.\n",
      "Norm: 729.43, NNZs: 50, Bias: -30.374997, T: 190254, Avg. loss: 1647.958947\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 3\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "Norm: 491.96, NNZs: 50, Bias: -26.107345, T: 475635, Avg. loss: 795.156043\n",
      "Norm: 978.24, NNZs: 50, Bias: 67.336990, T: 95127, Avg. loss: 3682.161822\n",
      "Norm: 485.87, NNZs: 50, Bias: -20.202252, T: 475635, Avg. loss: 759.850329\n",
      "Total training time: 1.64 seconds.\n",
      "Total training time: 0.31 seconds.\n",
      "Norm: 746.54, NNZs: 50, Bias: -19.548464, T: 190254, Avg. loss: 1782.824915\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 747.66, NNZs: 50, Bias: -13.815434, T: 190254, Avg. loss: 1819.711200\n",
      "Norm: 622.20, NNZs: 50, Bias: -33.641250, T: 285381, Avg. loss: 1269.623703\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 548.11, NNZs: 50, Bias: -34.408401, T: 380508, Avg. loss: 994.555922\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 615.80, NNZs: 50, Bias: -34.271140, T: 285381, Avg. loss: 1170.051051\n",
      "Norm: 633.77, NNZs: 50, Bias: -27.916215, T: 285381, Avg. loss: 1324.382852\n",
      "Norm: 546.41, NNZs: 50, Bias: -27.186550, T: 380508, Avg. loss: 917.488797\n",
      "Total training time: 0.88 seconds.\n",
      "Norm: 968.91, NNZs: 50, Bias: 32.787024, T: 95127, Avg. loss: 3308.801165\n",
      "Total training time: 0.97 seconds.\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "Total training time: 1.22 seconds.\n",
      "Norm: 745.54, NNZs: 50, Bias: -11.291322, T: 190254, Avg. loss: 2026.074486\n",
      "-- Epoch 2\n",
      "-- Epoch 5\n",
      "Total training time: 0.59 seconds.\n",
      "Norm: 618.73, NNZs: 50, Bias: -31.868557, T: 285381, Avg. loss: 1260.124360\n",
      "Total training time: 0.94 seconds.\n",
      "Norm: 543.58, NNZs: 50, Bias: -27.600012, T: 380508, Avg. loss: 989.248559\n",
      "-- Epoch 3\n",
      "Norm: 629.99, NNZs: 50, Bias: -36.353045, T: 285381, Avg. loss: 1285.743508\n",
      "-- Epoch 1\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 491.37, NNZs: 50, Bias: -26.164974, T: 475635, Avg. loss: 818.010672\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 541.60, NNZs: 50, Bias: -31.626087, T: 380508, Avg. loss: 914.632128\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 552.21, NNZs: 50, Bias: -30.304828, T: 380508, Avg. loss: 1029.830104\n",
      "Norm: 970.96, NNZs: 50, Bias: -10.802856, T: 95127, Avg. loss: 3282.318440\n",
      "Total training time: 1.15 seconds.\n",
      "Norm: 495.49, NNZs: 50, Bias: -25.204595, T: 475635, Avg. loss: 756.787561\n",
      "-- Epoch 5\n",
      "Total training time: 0.34 seconds.\n",
      "Total training time: 1.55 seconds.\n",
      "Norm: 750.21, NNZs: 50, Bias: -16.312384, T: 190254, Avg. loss: 1845.869725\n",
      "-- Epoch 2\n",
      "Norm: 628.89, NNZs: 50, Bias: -21.160283, T: 285381, Avg. loss: 1421.210785\n",
      "Total training time: 1.34 seconds.\n",
      "Total training time: 0.62 seconds.\n",
      "Norm: 954.86, NNZs: 50, Bias: 48.340920, T: 95127, Avg. loss: 3269.020675\n",
      "-- Epoch 3\n",
      "Total training time: 0.89 seconds.\n",
      "Norm: 544.76, NNZs: 50, Bias: -28.861468, T: 380508, Avg. loss: 981.073899\n",
      "-- Epoch 5\n",
      "Norm: 486.36, NNZs: 50, Bias: -23.294121, T: 475635, Avg. loss: 813.344725\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.27 seconds.\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 978.43, NNZs: 50, Bias: 83.473095, T: 95127, Avg. loss: 3688.848316\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Total training time: 0.29 seconds.\n",
      "Norm: 484.36, NNZs: 50, Bias: -29.871593, T: 475635, Avg. loss: 754.462514\n",
      "Norm: 963.29, NNZs: 50, Bias: 38.696352, T: 95127, Avg. loss: 3002.691949\n",
      "-- Epoch 2\n",
      "Norm: 550.03, NNZs: 50, Bias: -29.841778, T: 380508, Avg. loss: 1001.797939\n",
      "Total training time: 0.37 seconds.\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 623.31, NNZs: 50, Bias: -27.111610, T: 285381, Avg. loss: 1301.800668\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 739.95, NNZs: 50, Bias: -10.863751, T: 190254, Avg. loss: 1827.584121\n",
      "Norm: 754.17, NNZs: 50, Bias: -39.242457, T: 190254, Avg. loss: 1838.358685\n",
      "Total training time: 0.50 seconds.\n",
      "Norm: 552.84, NNZs: 50, Bias: -26.806169, T: 380508, Avg. loss: 1102.738377\n",
      "Norm: 488.79, NNZs: 50, Bias: -26.641288, T: 475635, Avg. loss: 806.869762\n",
      "Norm: 496.63, NNZs: 50, Bias: -26.003193, T: 475635, Avg. loss: 845.806040\n",
      "Total training time: 0.67 seconds.\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 1.68 seconds.\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "Norm: 958.27, NNZs: 50, Bias: 40.039404, T: 95127, Avg. loss: 3289.022411\n",
      "Total training time: 0.27 seconds.\n",
      "Norm: 734.50, NNZs: 50, Bias: -26.733160, T: 190254, Avg. loss: 2036.060158\n",
      "-- Epoch 2\n",
      "Norm: 547.67, NNZs: 50, Bias: -28.761449, T: 380508, Avg. loss: 1012.998267\n",
      "Total training time: 0.61 seconds.\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 493.91, NNZs: 50, Bias: -27.472456, T: 475635, Avg. loss: 824.159849\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 992.47, NNZs: 50, Bias: 27.423393, T: 95127, Avg. loss: 3366.500656\n",
      "Total training time: 0.33 seconds.\n",
      "Norm: 622.26, NNZs: 50, Bias: -24.507119, T: 285381, Avg. loss: 1290.987061\n",
      "Norm: 741.43, NNZs: 50, Bias: -18.744325, T: 190254, Avg. loss: 1690.482561\n",
      "-- Epoch 2\n",
      "Norm: 644.95, NNZs: 50, Bias: -33.814716, T: 285381, Avg. loss: 1301.053589\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.95 seconds.\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 496.78, NNZs: 50, Bias: -25.738428, T: 475635, Avg. loss: 904.733651\n",
      "-- Epoch 3\n",
      "Norm: 969.52, NNZs: 50, Bias: -13.811774, T: 95127, Avg. loss: 3111.761351\n",
      "-- Epoch 1\n",
      "Total training time: 1.51 seconds.\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 631.03, NNZs: 50, Bias: -28.728733, T: 285381, Avg. loss: 1434.626682\n",
      "Norm: 732.95, NNZs: 50, Bias: -39.868193, T: 190254, Avg. loss: 1828.800204\n",
      "Total training time: 0.91 seconds.\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Norm: 625.07, NNZs: 50, Bias: -26.711247, T: 285381, Avg. loss: 1198.271091\n",
      "-- Epoch 4\n",
      "Norm: 545.94, NNZs: 50, Bias: -29.044464, T: 380508, Avg. loss: 1005.157692\n",
      "Total training time: 0.97 seconds.\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 979.34, NNZs: 50, Bias: 42.049317, T: 95127, Avg. loss: 3071.743555\n",
      "-- Epoch 4\n",
      "Norm: 490.00, NNZs: 50, Bias: -24.584458, T: 475635, Avg. loss: 832.146127\n",
      "Norm: 561.95, NNZs: 50, Bias: -34.305068, T: 380508, Avg. loss: 1013.699494\n",
      "Total training time: 1.50 seconds.\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 758.68, NNZs: 50, Bias: -25.944664, T: 190254, Avg. loss: 1876.220837\n",
      "Total training time: 1.27 seconds.\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 737.89, NNZs: 50, Bias: -39.734940, T: 190254, Avg. loss: 1747.294128\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 556.34, NNZs: 50, Bias: -30.825592, T: 380508, Avg. loss: 1114.425527\n",
      "Norm: 619.70, NNZs: 50, Bias: -40.373071, T: 285381, Avg. loss: 1289.388555\n",
      "-- Epoch 3\n",
      "Total training time: 1.22 seconds.\n",
      "Norm: 544.97, NNZs: 50, Bias: -20.213250, T: 380508, Avg. loss: 934.781604\n",
      "Norm: 982.57, NNZs: 50, Bias: -1.138695, T: 95127, Avg. loss: 3145.874719\n",
      "Total training time: 0.93 seconds.\n",
      "Norm: 489.24, NNZs: 50, Bias: -26.972418, T: 475635, Avg. loss: 826.513636\n",
      "-- Epoch 5\n",
      "Total training time: 1.27 seconds.\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Total training time: 1.35 seconds.\n",
      "Norm: 502.21, NNZs: 50, Bias: -29.763321, T: 475635, Avg. loss: 833.410590\n",
      "-- Epoch 2\n",
      "Total training time: 1.55 seconds.\n",
      "Norm: 982.54, NNZs: 50, Bias: 72.020746, T: 95127, Avg. loss: 3105.194993\n",
      "Norm: 751.10, NNZs: 50, Bias: -22.424731, T: 190254, Avg. loss: 1731.239642\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.58 seconds.\n",
      "Norm: 977.15, NNZs: 50, Bias: 27.750466, T: 95127, Avg. loss: 2986.536310\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 628.22, NNZs: 50, Bias: -32.677323, T: 285381, Avg. loss: 1237.822343\n",
      "-- Epoch 2\n",
      "-- Epoch 1\n",
      "Norm: 636.63, NNZs: 50, Bias: -27.381182, T: 285381, Avg. loss: 1323.897975\n",
      "Norm: 964.23, NNZs: 50, Bias: -6.075172, T: 95127, Avg. loss: 3119.091974\n",
      "Total training time: 0.97 seconds.\n",
      "Total training time: 1.11 seconds.\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 2\n",
      "Norm: 499.51, NNZs: 50, Bias: -27.242747, T: 475635, Avg. loss: 914.160381\n",
      "-- Epoch 4\n",
      "Norm: 489.62, NNZs: 50, Bias: -15.552055, T: 475635, Avg. loss: 770.443265\n",
      "Total training time: 1.53 seconds.\n",
      "Norm: 542.99, NNZs: 50, Bias: -35.478824, T: 380508, Avg. loss: 1004.042255\n",
      "Norm: 748.77, NNZs: 50, Bias: -18.807890, T: 190254, Avg. loss: 1766.244890\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 740.76, NNZs: 50, Bias: -19.101023, T: 190254, Avg. loss: 1737.096145\n",
      "Total training time: 1.61 seconds.\n",
      "Total training time: 0.68 seconds.\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 754.26, NNZs: 50, Bias: -15.469088, T: 190254, Avg. loss: 1682.827976\n",
      "-- Epoch 1\n",
      "Norm: 628.25, NNZs: 50, Bias: -28.808653, T: 285381, Avg. loss: 1226.228738\n",
      "-- Epoch 3\n",
      "Norm: 548.27, NNZs: 50, Bias: -32.728818, T: 380508, Avg. loss: 964.306352\n",
      "Total training time: 0.42 seconds.\n",
      "Total training time: 1.20 seconds.\n",
      "Norm: 557.03, NNZs: 50, Bias: -30.669082, T: 380508, Avg. loss: 1030.109289\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "Norm: 977.85, NNZs: 50, Bias: 26.532665, T: 95127, Avg. loss: 3277.598056\n",
      "Total training time: 1.37 seconds.\n",
      "Norm: 743.33, NNZs: 50, Bias: -25.908616, T: 190254, Avg. loss: 1756.870169\n",
      "Total training time: 0.29 seconds.\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "-- Epoch 1\n",
      "Norm: 629.78, NNZs: 50, Bias: -33.266499, T: 285381, Avg. loss: 1247.365484\n",
      "Norm: 944.34, NNZs: 50, Bias: -2.245162, T: 95127, Avg. loss: 3048.663027\n",
      "Total training time: 0.95 seconds.\n",
      "Norm: 498.15, NNZs: 50, Bias: -28.122100, T: 475635, Avg. loss: 846.804863\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 621.33, NNZs: 50, Bias: -32.954696, T: 285381, Avg. loss: 1229.294879\n",
      "Norm: 487.04, NNZs: 50, Bias: -31.461829, T: 475635, Avg. loss: 825.868256\n",
      "-- Epoch 2\n",
      "Norm: 493.25, NNZs: 50, Bias: -26.225628, T: 475635, Avg. loss: 793.855860\n",
      "Total training time: 1.64 seconds.\n",
      "Norm: 547.21, NNZs: 50, Bias: -22.299857, T: 380508, Avg. loss: 955.719809\n",
      "Total training time: 0.82 seconds.\n",
      "Total training time: 1.44 seconds.\n",
      "Norm: 626.78, NNZs: 50, Bias: -25.842432, T: 285381, Avg. loss: 1242.399417\n",
      "Norm: 635.51, NNZs: 50, Bias: -28.735773, T: 285381, Avg. loss: 1192.664961\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "Total training time: 0.72 seconds.\n",
      "Norm: 753.32, NNZs: 50, Bias: -27.425260, T: 190254, Avg. loss: 1829.575693\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Total training time: 0.59 seconds.\n",
      "Norm: 975.43, NNZs: 50, Bias: 49.187412, T: 95127, Avg. loss: 2906.706921\n",
      "Norm: 550.97, NNZs: 50, Bias: -25.913700, T: 380508, Avg. loss: 972.378080\n",
      "-- Epoch 3\n",
      "Total training time: 0.42 seconds.\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 1\n",
      "Norm: 543.13, NNZs: 50, Bias: -24.145469, T: 380508, Avg. loss: 958.992712\n",
      "Norm: 741.29, NNZs: 50, Bias: -20.300008, T: 190254, Avg. loss: 1721.292917\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Total training time: 1.07 seconds.\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 550.56, NNZs: 50, Bias: -27.186602, T: 380508, Avg. loss: 968.674716\n",
      "-- Epoch 3\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 975.83, NNZs: 50, Bias: -14.698260, T: 95127, Avg. loss: 3148.684998\n",
      "Norm: 553.18, NNZs: 50, Bias: -31.472783, T: 380508, Avg. loss: 931.402517\n",
      "Norm: 492.38, NNZs: 50, Bias: -21.012168, T: 475635, Avg. loss: 786.906913\n",
      "Total training time: 0.40 seconds.\n",
      "Total training time: 1.14 seconds.\n",
      "Norm: 491.86, NNZs: 50, Bias: -23.613999, T: 475635, Avg. loss: 799.482738\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Total training time: 1.58 seconds.\n",
      "Total training time: 1.48 seconds.\n",
      "Norm: 968.17, NNZs: 50, Bias: 43.504093, T: 95127, Avg. loss: 3266.035165\n",
      "Norm: 488.15, NNZs: 50, Bias: -25.248469, T: 475635, Avg. loss: 788.498166\n",
      "Norm: 628.10, NNZs: 50, Bias: -32.520087, T: 285381, Avg. loss: 1291.653960\n",
      "Norm: 754.91, NNZs: 50, Bias: -15.110924, T: 190254, Avg. loss: 1651.612491\n",
      "Total training time: 1.33 seconds.\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 1\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "Total training time: 1.01 seconds.\n",
      "Norm: 619.82, NNZs: 50, Bias: -33.416663, T: 285381, Avg. loss: 1216.680438\n",
      "Norm: 493.94, NNZs: 50, Bias: -26.851155, T: 475635, Avg. loss: 796.720977\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 969.24, NNZs: 50, Bias: 40.392575, T: 95127, Avg. loss: 2975.964684\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 939.90, NNZs: 50, Bias: 72.533958, T: 95127, Avg. loss: 3057.837443\n",
      "Total training time: 0.34 seconds.\n",
      "Norm: 754.19, NNZs: 50, Bias: -32.858147, T: 190254, Avg. loss: 1771.236090\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 3\n",
      "Norm: 496.14, NNZs: 50, Bias: -24.248915, T: 475635, Avg. loss: 767.256103\n",
      "-- Epoch 1\n",
      "Norm: 956.77, NNZs: 50, Bias: 29.551475, T: 95127, Avg. loss: 2883.694218\n",
      "-- Epoch 1\n",
      "Total training time: 0.29 seconds.\n",
      "Norm: 550.95, NNZs: 50, Bias: -29.673805, T: 380508, Avg. loss: 1005.958910\n",
      "Total training time: 1.45 seconds.\n",
      "Norm: 627.80, NNZs: 50, Bias: -26.757578, T: 285381, Avg. loss: 1168.838037\n",
      "Total training time: 1.08 seconds.\n",
      "Norm: 744.47, NNZs: 50, Bias: -12.427548, T: 190254, Avg. loss: 1830.946410\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Norm: 543.09, NNZs: 50, Bias: -26.253643, T: 380508, Avg. loss: 949.053165\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "Norm: 640.85, NNZs: 50, Bias: -34.714500, T: 285381, Avg. loss: 1255.171421\n",
      "Total training time: 1.25 seconds.\n",
      "Total training time: 0.92 seconds.\n",
      "Norm: 736.71, NNZs: 50, Bias: -20.992933, T: 190254, Avg. loss: 1673.547799\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 969.44, NNZs: 50, Bias: 31.064779, T: 95127, Avg. loss: 3454.537236\n",
      "Norm: 728.31, NNZs: 50, Bias: -13.363926, T: 190254, Avg. loss: 1727.389829\n",
      "Norm: 971.05, NNZs: 50, Bias: 9.793569, T: 95127, Avg. loss: 3072.313957\n",
      "Total training time: 0.27 seconds.\n",
      "Total training time: 0.66 seconds.\n",
      "Norm: 550.91, NNZs: 50, Bias: -29.276068, T: 380508, Avg. loss: 915.454229\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 741.34, NNZs: 50, Bias: -24.352358, T: 190254, Avg. loss: 1638.316915\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Norm: 946.41, NNZs: 50, Bias: 12.710479, T: 95127, Avg. loss: 3108.622127\n",
      "Total training time: 0.61 seconds.\n",
      "Norm: 493.82, NNZs: 50, Bias: -23.581023, T: 475635, Avg. loss: 827.345545\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "Total training time: 1.64 seconds.\n",
      "Norm: 629.05, NNZs: 50, Bias: -22.124216, T: 285381, Avg. loss: 1293.569352\n",
      "Norm: 618.73, NNZs: 50, Bias: -28.929819, T: 285381, Avg. loss: 1186.263460\n",
      "Total training time: 0.90 seconds.\n",
      "Total training time: 0.98 seconds.\n",
      "Norm: 560.72, NNZs: 50, Bias: -28.376438, T: 380508, Avg. loss: 979.572770\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Norm: 490.10, NNZs: 50, Bias: -23.861930, T: 475635, Avg. loss: 781.925867\n",
      "Norm: 746.11, NNZs: 50, Bias: -17.621773, T: 190254, Avg. loss: 1915.739265\n",
      "Norm: 620.21, NNZs: 50, Bias: -14.390692, T: 285381, Avg. loss: 1223.888205\n",
      "Total training time: 0.54 seconds.\n",
      "Norm: 751.90, NNZs: 50, Bias: -30.820372, T: 190254, Avg. loss: 1722.777338\n",
      "Total training time: 0.94 seconds.\n",
      "Total training time: 0.56 seconds.\n",
      "Norm: 624.52, NNZs: 50, Bias: -25.211536, T: 285381, Avg. loss: 1163.083883\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "-- Epoch 3\n",
      "Total training time: 1.59 seconds.\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 977.80, NNZs: 50, Bias: -5.584504, T: 95127, Avg. loss: 3095.046505\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 2\n",
      "Norm: 501.76, NNZs: 50, Bias: -23.378595, T: 475635, Avg. loss: 806.093331\n",
      "Norm: 497.32, NNZs: 50, Bias: -24.072232, T: 475635, Avg. loss: 755.296781\n",
      "Total training time: 1.68 seconds.\n",
      "Norm: 539.41, NNZs: 50, Bias: -28.094435, T: 380508, Avg. loss: 925.949944\n",
      "Total training time: 1.40 seconds.\n",
      "Total training time: 1.20 seconds.\n",
      "Norm: 550.42, NNZs: 50, Bias: -18.196386, T: 380508, Avg. loss: 1007.760006\n",
      "Norm: 538.94, NNZs: 50, Bias: -20.747422, T: 380508, Avg. loss: 954.802526\n",
      "Norm: 965.54, NNZs: 50, Bias: 7.569867, T: 95127, Avg. loss: 3020.504900\n",
      "Norm: 730.23, NNZs: 50, Bias: -28.488911, T: 190254, Avg. loss: 1745.520143\n",
      "Norm: 970.55, NNZs: 50, Bias: -4.419279, T: 95127, Avg. loss: 3052.233292\n",
      "Norm: 626.16, NNZs: 50, Bias: -30.045985, T: 285381, Avg. loss: 1349.035520\n",
      "Total training time: 0.69 seconds.\n",
      "Total training time: 0.23 seconds.\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.34 seconds.\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 629.21, NNZs: 50, Bias: -28.978934, T: 285381, Avg. loss: 1218.859694\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "-- Epoch 4\n",
      "Norm: 546.72, NNZs: 50, Bias: -18.743474, T: 380508, Avg. loss: 910.621025\n",
      "Total training time: 1.19 seconds.\n",
      "Norm: 746.81, NNZs: 50, Bias: -31.047979, T: 190254, Avg. loss: 1740.447013\n",
      "-- Epoch 5\n",
      "Total training time: 0.64 seconds.\n",
      "Norm: 618.64, NNZs: 50, Bias: -24.138590, T: 285381, Avg. loss: 1236.717105\n",
      "Norm: 487.64, NNZs: 50, Bias: -26.609445, T: 475635, Avg. loss: 763.253367\n",
      "-- Epoch 3\n",
      "Norm: 748.78, NNZs: 50, Bias: -19.221266, T: 190254, Avg. loss: 1729.290036\n",
      "Norm: 492.45, NNZs: 50, Bias: -20.689327, T: 475635, Avg. loss: 828.971188\n",
      "Norm: 737.16, NNZs: 50, Bias: -23.703586, T: 190254, Avg. loss: 1690.943694\n",
      "Total training time: 0.59 seconds.\n",
      "Total training time: 1.52 seconds.\n",
      "Total training time: 0.48 seconds.\n",
      "Total training time: 0.93 seconds.\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 3\n",
      "Norm: 962.42, NNZs: 50, Bias: -13.853364, T: 95127, Avg. loss: 3266.598817\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 487.62, NNZs: 50, Bias: -18.281764, T: 475635, Avg. loss: 786.403728\n",
      "Norm: 556.28, NNZs: 50, Bias: -27.060526, T: 380508, Avg. loss: 1050.594389\n",
      "-- Epoch 2\n",
      "Norm: 978.13, NNZs: 50, Bias: 30.867227, T: 95127, Avg. loss: 3130.489020\n",
      "Norm: 548.49, NNZs: 50, Bias: -36.454567, T: 380508, Avg. loss: 949.580935\n",
      "Total training time: 1.53 seconds.\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 1.16 seconds.\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 5\n",
      "Norm: 619.90, NNZs: 50, Bias: -39.041131, T: 285381, Avg. loss: 1228.077084\n",
      "Norm: 486.98, NNZs: 50, Bias: -19.847460, T: 475635, Avg. loss: 751.088744\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.51 seconds.\n",
      "Norm: 626.86, NNZs: 50, Bias: -29.896028, T: 285381, Avg. loss: 1224.669262\n",
      "Norm: 543.88, NNZs: 50, Bias: -26.951863, T: 380508, Avg. loss: 965.283317\n",
      "Norm: 749.22, NNZs: 50, Bias: -26.742679, T: 190254, Avg. loss: 1833.979002\n",
      "Total training time: 0.75 seconds.\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 498.78, NNZs: 50, Bias: -25.424753, T: 475635, Avg. loss: 863.185392\n",
      "Norm: 625.01, NNZs: 50, Bias: -32.174806, T: 285381, Avg. loss: 1201.468663\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 1\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 737.67, NNZs: 50, Bias: -25.984823, T: 190254, Avg. loss: 1744.189483\n",
      "Norm: 495.54, NNZs: 50, Bias: -27.752077, T: 475635, Avg. loss: 782.814266\n",
      "-- Epoch 1\n",
      "Total training time: 1.51 seconds.\n",
      "Total training time: 0.70 seconds.\n",
      "Norm: 546.24, NNZs: 50, Bias: -28.354564, T: 380508, Avg. loss: 958.668477\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "Norm: 490.32, NNZs: 50, Bias: -24.855115, T: 475635, Avg. loss: 794.351175\n",
      "Norm: 548.15, NNZs: 50, Bias: -30.389676, T: 380508, Avg. loss: 954.810359\n",
      "Norm: 632.29, NNZs: 50, Bias: -34.928378, T: 285381, Avg. loss: 1297.194875\n",
      "Total training time: 1.04 seconds.\n",
      "Total training time: 1.53 seconds.\n",
      "Norm: 943.11, NNZs: 50, Bias: 17.778909, T: 95127, Avg. loss: 2988.376975\n",
      "Norm: 968.24, NNZs: 50, Bias: 61.355200, T: 95127, Avg. loss: 3120.736505\n",
      "Norm: 543.37, NNZs: 50, Bias: -34.315095, T: 380508, Avg. loss: 937.679739\n",
      "-- Epoch 5\n",
      "Total training time: 0.24 seconds.\n",
      "Total training time: 0.31 seconds.\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 2\n",
      "Norm: 965.54, NNZs: 50, Bias: 33.329619, T: 95127, Avg. loss: 3053.088568\n",
      "-- Epoch 5\n",
      "Norm: 966.78, NNZs: 50, Bias: -3.387517, T: 95127, Avg. loss: 2972.513461\n",
      "Total training time: 0.33 seconds.\n",
      "Norm: 626.13, NNZs: 50, Bias: -30.138725, T: 285381, Avg. loss: 1235.076270\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 486.94, NNZs: 50, Bias: -32.268154, T: 475635, Avg. loss: 788.408307\n",
      "-- Epoch 4\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 493.10, NNZs: 50, Bias: -26.957786, T: 475635, Avg. loss: 786.427812\n",
      "Norm: 486.51, NNZs: 50, Bias: -29.433845, T: 475635, Avg. loss: 773.087630\n",
      "Total training time: 1.43 seconds.\n",
      "Norm: 550.44, NNZs: 50, Bias: -35.768763, T: 380508, Avg. loss: 1009.648901\n",
      "Total training time: 1.50 seconds.\n",
      "Norm: 741.56, NNZs: 50, Bias: -12.585791, T: 190254, Avg. loss: 1751.723001\n",
      "Total training time: 0.56 seconds.\n",
      "Total training time: 1.30 seconds.\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "Norm: 727.57, NNZs: 50, Bias: -17.213369, T: 190254, Avg. loss: 1688.614793\n",
      "Total training time: 0.60 seconds.\n",
      "Norm: 990.23, NNZs: 50, Bias: -2.502948, T: 95127, Avg. loss: 3304.668695\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 743.38, NNZs: 50, Bias: -34.790537, T: 190254, Avg. loss: 1719.384315\n",
      "Total training time: 0.64 seconds.\n",
      "Norm: 547.68, NNZs: 50, Bias: -29.013919, T: 380508, Avg. loss: 962.596142\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "Norm: 745.58, NNZs: 50, Bias: -30.548029, T: 190254, Avg. loss: 1688.010623\n",
      "-- Epoch 3\n",
      "Norm: 977.33, NNZs: 50, Bias: 5.336732, T: 95127, Avg. loss: 2877.055008\n",
      "Total training time: 1.27 seconds.\n",
      "Total training time: 0.64 seconds.\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 627.04, NNZs: 50, Bias: -17.998624, T: 285381, Avg. loss: 1239.653048\n",
      "-- Epoch 3\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "Norm: 494.84, NNZs: 50, Bias: -24.452374, T: 475635, Avg. loss: 830.576492\n",
      "Norm: 971.38, NNZs: 50, Bias: 11.722656, T: 95127, Avg. loss: 2986.144526\n",
      "Total training time: 1.39 seconds.\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 613.12, NNZs: 50, Bias: -22.190838, T: 285381, Avg. loss: 1198.962917\n",
      "-- Epoch 2\n",
      "Norm: 746.66, NNZs: 50, Bias: -43.574761, T: 190254, Avg. loss: 1841.005630\n",
      "Total training time: 0.57 seconds.\n",
      "Norm: 625.73, NNZs: 50, Bias: -36.942248, T: 285381, Avg. loss: 1218.190430\n",
      "-- Epoch 3\n",
      "-- Epoch 1\n",
      "Norm: 552.10, NNZs: 50, Bias: -26.004014, T: 380508, Avg. loss: 968.206129\n",
      "Norm: 741.34, NNZs: 50, Bias: -34.900351, T: 190254, Avg. loss: 1631.943915\n",
      "Total training time: 0.99 seconds.\n",
      "Norm: 627.47, NNZs: 50, Bias: -29.984444, T: 285381, Avg. loss: 1195.845543\n",
      "-- Epoch 1\n",
      "Total training time: 0.94 seconds.\n",
      "Norm: 490.36, NNZs: 50, Bias: -29.086763, T: 475635, Avg. loss: 792.532154\n",
      "-- Epoch 4\n",
      "Total training time: 0.62 seconds.\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 953.40, NNZs: 50, Bias: 3.683042, T: 95127, Avg. loss: 3127.453335\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 743.91, NNZs: 50, Bias: -23.753580, T: 190254, Avg. loss: 1681.602037\n",
      "Norm: 961.56, NNZs: 50, Bias: 36.148873, T: 95127, Avg. loss: 3240.500879\n",
      "Norm: 977.00, NNZs: 50, Bias: 40.266084, T: 95127, Avg. loss: 3141.050067\n",
      "Total training time: 0.57 seconds.\n",
      "Total training time: 0.32 seconds.\n",
      "Total training time: 0.26 seconds.\n",
      "Norm: 635.83, NNZs: 50, Bias: -37.863654, T: 285381, Avg. loss: 1301.297001\n",
      "-- Epoch 2\n",
      "Norm: 533.98, NNZs: 50, Bias: -26.794518, T: 380508, Avg. loss: 934.633122\n",
      "-- Epoch 3\n",
      "Total training time: 0.87 seconds.\n",
      "Norm: 548.43, NNZs: 50, Bias: -28.256850, T: 380508, Avg. loss: 949.819440\n",
      "Norm: 967.62, NNZs: 50, Bias: -17.429297, T: 95127, Avg. loss: 3384.289833\n",
      "-- Epoch 2\n",
      "-- Epoch 1\n",
      "Total training time: 0.29 seconds.\n",
      "Norm: 547.91, NNZs: 50, Bias: -34.750739, T: 380508, Avg. loss: 932.781037\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 2\n",
      "-- Epoch 5\n",
      "Total training time: 1.23 seconds.\n",
      "Norm: 622.01, NNZs: 50, Bias: -32.977691, T: 285381, Avg. loss: 1159.208143\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.31 seconds.\n",
      "Norm: 735.20, NNZs: 50, Bias: -27.523035, T: 190254, Avg. loss: 1757.101704\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 494.78, NNZs: 50, Bias: -24.596554, T: 475635, Avg. loss: 797.079072\n",
      "-- Epoch 5\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Norm: 750.30, NNZs: 50, Bias: -21.523490, T: 190254, Avg. loss: 1812.570732\n",
      "Total training time: 1.45 seconds.\n",
      "Total training time: 0.57 seconds.\n",
      "Norm: 621.53, NNZs: 50, Bias: -22.346104, T: 285381, Avg. loss: 1192.935494\n",
      "-- Epoch 3\n",
      "Norm: 742.99, NNZs: 50, Bias: -37.374657, T: 190254, Avg. loss: 1886.379499\n",
      "Norm: 556.07, NNZs: 50, Bias: -36.115716, T: 380508, Avg. loss: 1012.522464\n",
      "Total training time: 1.16 seconds.\n",
      "Total training time: 0.87 seconds.\n",
      "Norm: 491.34, NNZs: 50, Bias: -26.627208, T: 475635, Avg. loss: 768.485183\n",
      "Total training time: 1.48 seconds.\n",
      "Norm: 967.20, NNZs: 50, Bias: -11.238405, T: 95127, Avg. loss: 3347.322202\n",
      "Norm: 490.51, NNZs: 50, Bias: -24.684826, T: 475635, Avg. loss: 781.559225\n",
      "Norm: 743.97, NNZs: 50, Bias: -25.466186, T: 190254, Avg. loss: 1764.795267\n",
      "Norm: 483.74, NNZs: 50, Bias: -22.663253, T: 475635, Avg. loss: 770.484906\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.31 seconds.\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.58 seconds.\n",
      "Norm: 550.20, NNZs: 50, Bias: -29.278854, T: 380508, Avg. loss: 907.093545\n",
      "-- Epoch 3\n",
      "Norm: 624.07, NNZs: 50, Bias: -28.531934, T: 285381, Avg. loss: 1245.097178\n",
      "-- Epoch 2\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 977.84, NNZs: 50, Bias: 58.916807, T: 95127, Avg. loss: 3021.154851\n",
      "Norm: 976.61, NNZs: 50, Bias: 61.801807, T: 95127, Avg. loss: 3049.329757\n",
      "Total training time: 0.90 seconds.\n",
      "Norm: 638.05, NNZs: 50, Bias: -23.302578, T: 285381, Avg. loss: 1278.608565\n",
      "Total training time: 0.35 seconds.\n",
      "Norm: 540.63, NNZs: 50, Bias: -24.400176, T: 380508, Avg. loss: 930.113457\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Norm: 756.51, NNZs: 50, Bias: -18.799325, T: 190254, Avg. loss: 1873.362196\n",
      "-- Epoch 2\n",
      "Total training time: 0.56 seconds.\n",
      "Norm: 500.03, NNZs: 50, Bias: -30.493329, T: 475635, Avg. loss: 833.167896\n",
      "-- Epoch 1\n",
      "Total training time: 1.47 seconds.\n",
      "Norm: 624.16, NNZs: 50, Bias: -38.450994, T: 285381, Avg. loss: 1250.617920\n",
      "-- Epoch 3\n",
      "Norm: 494.48, NNZs: 50, Bias: -27.311365, T: 475635, Avg. loss: 747.605013\n",
      "Total training time: 0.90 seconds.\n",
      "Norm: 629.04, NNZs: 50, Bias: -38.305343, T: 285381, Avg. loss: 1330.679054\n",
      "-- Epoch 4\n",
      "Total training time: 1.49 seconds.\n",
      "Norm: 545.28, NNZs: 50, Bias: -28.701679, T: 380508, Avg. loss: 969.446549\n",
      "Total training time: 0.95 seconds.\n",
      "Norm: 553.70, NNZs: 50, Bias: -26.102641, T: 380508, Avg. loss: 995.297673\n",
      "Norm: 485.43, NNZs: 50, Bias: -26.109466, T: 475635, Avg. loss: 766.380652\n",
      "Norm: 750.01, NNZs: 50, Bias: -0.805119, T: 190254, Avg. loss: 1719.175653\n",
      "Total training time: 1.21 seconds.\n",
      "Total training time: 1.11 seconds.\n",
      "Total training time: 1.36 seconds.\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 5\n",
      "Norm: 741.46, NNZs: 50, Bias: -12.270293, T: 190254, Avg. loss: 1703.770861\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 973.95, NNZs: 50, Bias: 84.455487, T: 95127, Avg. loss: 3368.587869\n",
      "-- Epoch 3\n",
      "Total training time: 0.31 seconds.\n",
      "Norm: 630.52, NNZs: 50, Bias: -27.707179, T: 285381, Avg. loss: 1318.360490\n",
      "-- Epoch 2\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 4\n",
      "Norm: 542.87, NNZs: 50, Bias: -34.635052, T: 380508, Avg. loss: 975.036391\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Norm: 489.09, NNZs: 50, Bias: -30.337245, T: 475635, Avg. loss: 798.045466\n",
      "Norm: 966.60, NNZs: 50, Bias: -36.870446, T: 95127, Avg. loss: 3155.364639\n",
      "Total training time: 1.53 seconds.\n",
      "Norm: 497.15, NNZs: 50, Bias: -26.112352, T: 475635, Avg. loss: 818.251451\n",
      "-- Epoch 1\n",
      "Total training time: 0.31 seconds.\n",
      "Total training time: 1.44 seconds.\n",
      "Norm: 631.50, NNZs: 50, Bias: -23.335115, T: 285381, Avg. loss: 1208.032602\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 548.87, NNZs: 50, Bias: -29.026301, T: 380508, Avg. loss: 1025.356335\n",
      "Norm: 550.74, NNZs: 50, Bias: -32.745316, T: 380508, Avg. loss: 1035.135825\n",
      "-- Epoch 1\n",
      "Total training time: 1.40 seconds.\n",
      "Norm: 971.98, NNZs: 50, Bias: 41.028300, T: 95127, Avg. loss: 3352.308426\n",
      "Norm: 620.52, NNZs: 50, Bias: -21.122613, T: 285381, Avg. loss: 1216.880203\n",
      "Total training time: 1.12 seconds.\n",
      "Norm: 748.98, NNZs: 50, Bias: -7.283523, T: 190254, Avg. loss: 1876.493402\n",
      "-- Epoch 4\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 5\n",
      "-- Epoch 4\n",
      "Norm: 490.61, NNZs: 50, Bias: -30.581406, T: 475635, Avg. loss: 802.706174\n",
      "Total training time: 0.20 seconds.\n",
      "Total training time: 0.62 seconds.\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "Norm: 968.31, NNZs: 50, Bias: 31.922546, T: 95127, Avg. loss: 2958.060574\n",
      "Norm: 980.46, NNZs: 50, Bias: 29.025399, T: 95127, Avg. loss: 3048.313676\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 752.06, NNZs: 50, Bias: -31.016152, T: 190254, Avg. loss: 1773.213138\n",
      "Norm: 492.39, NNZs: 50, Bias: -25.660352, T: 475635, Avg. loss: 842.395052\n",
      "Norm: 490.11, NNZs: 50, Bias: -32.007871, T: 475635, Avg. loss: 849.386083\n",
      "Total training time: 0.63 seconds.\n",
      "Norm: 554.69, NNZs: 50, Bias: -21.066044, T: 380508, Avg. loss: 943.443933\n",
      "Norm: 961.12, NNZs: 50, Bias: 61.093226, T: 95127, Avg. loss: 3059.592909\n",
      "Total training time: 1.68 seconds.\n",
      "Total training time: 1.40 seconds.\n",
      "Norm: 543.50, NNZs: 50, Bias: -16.218863, T: 380508, Avg. loss: 948.669883\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 626.92, NNZs: 50, Bias: -22.403116, T: 285381, Avg. loss: 1322.784186\n",
      "Norm: 740.75, NNZs: 50, Bias: -21.188062, T: 190254, Avg. loss: 1862.782492\n",
      "Total training time: 1.34 seconds.\n",
      "Total training time: 1.35 seconds.\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 3\n",
      "-- Epoch 2\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 752.27, NNZs: 50, Bias: -15.558642, T: 190254, Avg. loss: 1712.427339\n",
      "Norm: 738.78, NNZs: 50, Bias: -19.244621, T: 190254, Avg. loss: 1671.414137\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 3\n",
      "Norm: 626.62, NNZs: 50, Bias: -33.483488, T: 285381, Avg. loss: 1253.208882\n",
      "-- Epoch 1\n",
      "Norm: 496.18, NNZs: 50, Bias: -20.709634, T: 475635, Avg. loss: 777.103465\n",
      "Norm: 750.83, NNZs: 50, Bias: -0.458729, T: 190254, Avg. loss: 1721.776584\n",
      "Total training time: 0.93 seconds.\n",
      "Norm: 630.36, NNZs: 50, Bias: -24.270820, T: 285381, Avg. loss: 1313.414632\n",
      "-- Epoch 4\n",
      "Total training time: 0.58 seconds.\n",
      "Norm: 485.59, NNZs: 50, Bias: -17.627828, T: 475635, Avg. loss: 780.958536\n",
      "Total training time: 1.62 seconds.\n",
      "Norm: 980.60, NNZs: 50, Bias: 15.344388, T: 95127, Avg. loss: 3121.020478\n",
      "Total training time: 1.65 seconds.\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 3\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 550.83, NNZs: 50, Bias: -18.339369, T: 380508, Avg. loss: 1028.865568\n",
      "Norm: 621.69, NNZs: 50, Bias: -28.190726, T: 285381, Avg. loss: 1186.714608\n",
      "-- Epoch 1\n",
      "Total training time: 1.26 seconds.\n",
      "Total training time: 0.80 seconds.\n",
      "Norm: 960.97, NNZs: 50, Bias: 44.752536, T: 95127, Avg. loss: 3476.860315\n",
      "-- Epoch 5\n",
      "Norm: 630.36, NNZs: 50, Bias: -25.721611, T: 285381, Avg. loss: 1211.377911\n",
      "-- Epoch 4\n",
      "Norm: 547.93, NNZs: 50, Bias: -27.273290, T: 380508, Avg. loss: 976.409483\n",
      "Total training time: 0.41 seconds.\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Norm: 551.64, NNZs: 50, Bias: -23.459366, T: 380508, Avg. loss: 1021.065331\n",
      "-- Epoch 1\n",
      "Norm: 985.00, NNZs: 50, Bias: -41.257644, T: 95127, Avg. loss: 3124.389978\n",
      "Norm: 627.28, NNZs: 50, Bias: -24.440280, T: 285381, Avg. loss: 1219.922232\n",
      "Total training time: 0.86 seconds.\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 962.71, NNZs: 50, Bias: 26.652372, T: 95127, Avg. loss: 3080.152861\n",
      "-- Epoch 4\n",
      "Total training time: 1.00 seconds.\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 745.79, NNZs: 50, Bias: -23.226057, T: 190254, Avg. loss: 1753.508182\n",
      "Total training time: 0.35 seconds.\n",
      "Norm: 543.13, NNZs: 50, Bias: -25.290490, T: 380508, Avg. loss: 925.581323\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 2\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "-- Epoch 5\n",
      "Norm: 958.62, NNZs: 50, Bias: 36.338482, T: 95127, Avg. loss: 3059.233586\n",
      "Norm: 492.53, NNZs: 50, Bias: -23.445222, T: 475635, Avg. loss: 845.304103\n",
      "Norm: 741.32, NNZs: 50, Bias: -20.136734, T: 190254, Avg. loss: 1927.795631\n",
      "Norm: 493.08, NNZs: 50, Bias: -25.225762, T: 475635, Avg. loss: 803.471689\n",
      "Norm: 553.96, NNZs: 50, Bias: -25.652460, T: 380508, Avg. loss: 945.587566\n",
      "-- Epoch 1\n",
      "Total training time: 1.62 seconds.\n",
      "Total training time: 1.42 seconds.\n",
      "Total training time: 0.24 seconds.\n",
      "Norm: 974.83, NNZs: 50, Bias: 40.677031, T: 95127, Avg. loss: 3222.619289\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 0.71 seconds.\n",
      "Norm: 632.93, NNZs: 50, Bias: -31.403099, T: 285381, Avg. loss: 1242.987443\n",
      "Norm: 752.03, NNZs: 50, Bias: -28.776668, T: 190254, Avg. loss: 1752.516378\n",
      "Norm: 486.34, NNZs: 50, Bias: -24.907136, T: 475635, Avg. loss: 762.473785\n",
      "-- Epoch 3\n",
      "Total training time: 0.25 seconds.\n",
      "Norm: 742.07, NNZs: 50, Bias: -31.590717, T: 190254, Avg. loss: 1730.296819\n",
      "-- Epoch 2\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.44 seconds.\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 1\n",
      "-- Epoch 3\n",
      "Total training time: 1.26 seconds.\n",
      "Norm: 550.82, NNZs: 50, Bias: -26.389492, T: 380508, Avg. loss: 952.524224\n",
      "-- Epoch 3\n",
      "Total training time: 1.19 seconds.\n",
      "Norm: 491.86, NNZs: 50, Bias: -23.885551, T: 475635, Avg. loss: 838.347817\n",
      "Norm: 979.73, NNZs: 50, Bias: 47.006725, T: 95127, Avg. loss: 3214.270690\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.16 seconds.\n",
      "Norm: 621.10, NNZs: 50, Bias: -24.124405, T: 285381, Avg. loss: 1354.726532\n",
      "Total training time: 0.92 seconds.\n",
      "Norm: 973.31, NNZs: 50, Bias: -16.940274, T: 95127, Avg. loss: 3015.425414\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "-- Epoch 4\n",
      "-- Epoch 2\n",
      "Norm: 748.98, NNZs: 50, Bias: -12.235927, T: 190254, Avg. loss: 1809.709862\n",
      "Norm: 752.37, NNZs: 50, Bias: -20.158749, T: 190254, Avg. loss: 1726.359613\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Total training time: 0.54 seconds.\n",
      "Norm: 552.66, NNZs: 50, Bias: -30.642039, T: 380508, Avg. loss: 968.352286\n",
      "Norm: 493.34, NNZs: 50, Bias: -24.832487, T: 475635, Avg. loss: 778.250607\n",
      "-- Epoch 3\n",
      "Norm: 635.25, NNZs: 50, Bias: -34.079183, T: 285381, Avg. loss: 1243.556801\n",
      "Total training time: 0.72 seconds.\n",
      "Total training time: 1.47 seconds.\n",
      "Norm: 537.86, NNZs: 50, Bias: -28.192867, T: 380508, Avg. loss: 1052.448581\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 629.79, NNZs: 50, Bias: -29.686649, T: 285381, Avg. loss: 1225.989047\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 5\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 747.91, NNZs: 50, Bias: -35.938098, T: 190254, Avg. loss: 1706.352334\n",
      "Norm: 492.33, NNZs: 50, Bias: -24.166163, T: 475635, Avg. loss: 784.216100\n",
      "-- Epoch 1\n",
      "Total training time: 0.37 seconds.\n",
      "Norm: 747.40, NNZs: 50, Bias: -19.587711, T: 190254, Avg. loss: 1799.952982\n",
      "Norm: 628.85, NNZs: 50, Bias: -26.212149, T: 285381, Avg. loss: 1221.247111\n",
      "-- Epoch 4\n",
      "Total training time: 0.70 seconds.\n",
      "Total training time: 1.49 seconds.\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 629.17, NNZs: 50, Bias: -27.186265, T: 285381, Avg. loss: 1276.215420\n",
      "-- Epoch 3\n",
      "Norm: 554.02, NNZs: 50, Bias: -27.163816, T: 380508, Avg. loss: 967.924810\n",
      "Total training time: 0.68 seconds.\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "-- Epoch 4\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "Norm: 625.35, NNZs: 50, Bias: -39.210748, T: 285381, Avg. loss: 1209.366102\n",
      "Norm: 485.67, NNZs: 50, Bias: -25.955546, T: 475635, Avg. loss: 864.117321\n",
      "Norm: 493.90, NNZs: 50, Bias: -30.974598, T: 475635, Avg. loss: 797.717926\n",
      "Total training time: 0.52 seconds.\n",
      "Norm: 631.75, NNZs: 50, Bias: -33.596306, T: 285381, Avg. loss: 1272.306268\n",
      "Norm: 962.83, NNZs: 50, Bias: 12.383951, T: 95127, Avg. loss: 3063.216340\n",
      "-- Epoch 4\n",
      "Total training time: 1.25 seconds.\n",
      "Norm: 550.21, NNZs: 50, Bias: -26.978270, T: 380508, Avg. loss: 956.372429\n",
      "Norm: 553.16, NNZs: 50, Bias: -25.684941, T: 380508, Avg. loss: 953.550687\n",
      "Total training time: 1.35 seconds.\n",
      "Total training time: 0.23 seconds.\n",
      "Norm: 972.52, NNZs: 50, Bias: 26.475500, T: 95127, Avg. loss: 3185.356832\n",
      "Total training time: 0.90 seconds.\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 494.63, NNZs: 50, Bias: -22.003400, T: 475635, Avg. loss: 797.072534\n",
      "-- Epoch 5\n",
      "-- Epoch 5\n",
      "Total training time: 1.09 seconds.\n",
      "Norm: 745.58, NNZs: 50, Bias: -22.314557, T: 190254, Avg. loss: 1725.080512\n",
      "Norm: 549.51, NNZs: 50, Bias: -26.279797, T: 380508, Avg. loss: 993.016820\n",
      "Norm: 545.14, NNZs: 50, Bias: -27.698195, T: 380508, Avg. loss: 943.017398\n",
      "Total training time: 0.36 seconds.\n",
      "Total training time: 1.00 seconds.\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 5\n",
      "-- Epoch 5\n",
      "Norm: 552.80, NNZs: 50, Bias: -26.709273, T: 380508, Avg. loss: 991.376455\n",
      "Norm: 491.79, NNZs: 50, Bias: -28.872299, T: 475635, Avg. loss: 787.096436\n",
      "Norm: 496.27, NNZs: 50, Bias: -24.513462, T: 475635, Avg. loss: 785.177368\n",
      "Total training time: 0.86 seconds.\n",
      "Total training time: 1.38 seconds.\n",
      "Norm: 750.09, NNZs: 50, Bias: -19.372861, T: 190254, Avg. loss: 1792.084798\n",
      "-- Epoch 5\n",
      "Total training time: 1.13 seconds.\n",
      "Norm: 486.77, NNZs: 50, Bias: -27.191547, T: 475635, Avg. loss: 775.810781\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 493.47, NNZs: 50, Bias: -26.182053, T: 475635, Avg. loss: 816.228325\n",
      "Norm: 622.90, NNZs: 50, Bias: -23.168018, T: 285381, Avg. loss: 1222.490939\n",
      "Total training time: 0.92 seconds.\n",
      "Total training time: 0.57 seconds.\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 628.34, NNZs: 50, Bias: -35.192032, T: 285381, Avg. loss: 1267.857062\n",
      "Norm: 490.83, NNZs: 50, Bias: -31.414416, T: 475635, Avg. loss: 815.032215\n",
      "-- Epoch 1\n",
      "Total training time: 0.52 seconds.\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 4\n",
      "-- Epoch 1\n",
      "Norm: 964.65, NNZs: 50, Bias: 42.572488, T: 95127, Avg. loss: 3130.550486\n",
      "Norm: 546.09, NNZs: 50, Bias: -19.595934, T: 380508, Avg. loss: 955.365768\n",
      "Total training time: 0.81 seconds.\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 5\n",
      "-- Epoch 2\n",
      "Norm: 548.39, NNZs: 50, Bias: -27.413638, T: 380508, Avg. loss: 986.855836\n",
      "Norm: 491.46, NNZs: 50, Bias: -19.340873, T: 475635, Avg. loss: 786.385933\n",
      "Total training time: 0.90 seconds.\n",
      "Total training time: 0.75 seconds.\n",
      "Norm: 969.35, NNZs: 50, Bias: 42.814817, T: 95127, Avg. loss: 3134.119179\n",
      "Norm: 957.82, NNZs: 50, Bias: 80.724683, T: 95127, Avg. loss: 2957.155943\n",
      "-- Epoch 5\n",
      "Total training time: 0.22 seconds.\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 739.41, NNZs: 50, Bias: -21.736887, T: 190254, Avg. loss: 1758.338240\n",
      "-- Epoch 2\n",
      "-- Epoch 2\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 492.26, NNZs: 50, Bias: -26.538835, T: 475635, Avg. loss: 811.874795\n",
      "Total training time: 0.89 seconds.\n",
      "Norm: 737.92, NNZs: 50, Bias: -15.371101, T: 190254, Avg. loss: 1676.696047\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 617.84, NNZs: 50, Bias: -30.753266, T: 285381, Avg. loss: 1242.562593\n",
      "Norm: 740.22, NNZs: 50, Bias: -27.873343, T: 190254, Avg. loss: 1757.600511\n",
      "Total training time: 0.41 seconds.\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "-- Epoch 4\n",
      "Norm: 613.29, NNZs: 50, Bias: -25.512306, T: 285381, Avg. loss: 1187.838202\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 629.57, NNZs: 50, Bias: -28.338575, T: 285381, Avg. loss: 1244.502132\n",
      "Norm: 542.53, NNZs: 50, Bias: -26.255166, T: 380508, Avg. loss: 967.872942\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Total training time: 0.61 seconds.\n",
      "Norm: 540.13, NNZs: 50, Bias: -19.445511, T: 380508, Avg. loss: 928.333742\n",
      "-- Epoch 5\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 550.58, NNZs: 50, Bias: -27.230199, T: 380508, Avg. loss: 970.902456\n",
      "Norm: 488.70, NNZs: 50, Bias: -24.497006, T: 475635, Avg. loss: 796.294701\n",
      "Total training time: 0.75 seconds.\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 485.22, NNZs: 50, Bias: -20.783766, T: 475635, Avg. loss: 764.421463\n",
      "Total training time: 0.70 seconds.\n",
      "Norm: 494.66, NNZs: 50, Bias: -21.141251, T: 475635, Avg. loss: 799.150677\n",
      "Total training time: 0.85 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.88      0.87     17881\n",
      "          1       0.83      0.81      0.82     13829\n",
      "\n",
      "avg / total       0.85      0.85      0.85     31710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.2s finished\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_bagging_sgd_svm\n",
    "from classifier import train_SGD_SVM\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "bag_svm_clf = train_bagging_sgd_svm(X_train, y_train)\n",
    "predictions = bag_svm_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_bagging_svm\n",
    "\n",
    "bag_svm_clf = train_bagging_svm(X_train, y_train)\n",
    "predictions = bag_svm_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "svm_clf = train_svm(X_ctrain, y_train)\n",
    "predictions = svm_clf.predict(X_ctest)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 21.0min finished\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_ada_boost\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train_ = encode(X_train)\n",
    "\n",
    "dt_clf = train_ada_boost(X_train_,y_train)\n",
    "predictions = dt_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 20.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.901\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'sqrt'\n",
      "\tclf__n_estimators: 200\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.90      0.92      0.91      1378\n",
      "          1       0.90      0.88      0.89      1122\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_xtree_classifer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "xtree_clf = train_xtree_classifer(X_train,y_train)\n",
    "predictions = xtree_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)\n",
    "\n",
    "#clf = clf.fit(train, label)\n",
    "#predictions = clf.predict(X_quiz)\n",
    "#write_out(predictions,\"etc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f549b0bd590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAM4CAYAAADYpbShAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMwAANAQzAAA0Pj/bCMhD/6QoQ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f549ee0d790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "\n",
    "\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=300,max_depth=None, max_features='log2',random_state=0)\n",
    "xtree.fit(X_train1, y_train1)\n",
    "\n",
    "#Format the bar plot so that it is hip\n",
    "f, ax = plt.subplots(figsize=(12, 14))\n",
    "\n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False) \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "##########################################\n",
    "\n",
    "ax.bar(range(len(xtree.feature_importances_)), \n",
    "           xtree.feature_importances_, color=\"#3F5D7D\")\n",
    "ax.set_title(\"Feature Importances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '5', '7', '8', '9', '14', '16', '17', '18', '20', '23', '25', '26', '56', '57', '58']\n"
     ]
    }
   ],
   "source": [
    "pd.Series(X_train.columns).to_csv('data_col.csv')\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_bagging_xtree\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "bag_xtree_clf = train_bagging_xtree(X_train,y_train)\n",
    "predictions = bag_xtree_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:   54.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.817\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 300\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.84      0.86      0.85       695\n",
      "          1       0.82      0.80      0.81       555\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_decision_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "dt_clf = train_decision_tree(X_train,y_train)\n",
    "predictions = dt_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   20.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   34.6s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   35.3s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   36.4s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.1min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.1min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.1min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    7.3s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.5min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.5min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.5min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.7min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.7min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.7min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.0min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.878\n",
      "Best parameters set:\n",
      "\tclf__max_samples: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   17.1s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.90      0.90      0.90       748\n",
      "          1       0.85      0.84      0.85       502\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_bagging_decision_tree\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "bag_dt_clf = train_bagging_decision_tree(X_train, y_train)\n",
    "predictions = bag_dt_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   23.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.883\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'sqrt'\n",
      "\tclf__n_estimators: 30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.92      0.89       672\n",
      "          1       0.90      0.83      0.87       578\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from classifier import train_rf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf_clf = train_rf(X_train, y_train)\n",
    "predictions = rf_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classifer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classifier import train_nearest_neighbor\n",
    "\n",
    "nn_clf = train_nearest_neighbor(X_train,y_train)\n",
    "predictions = nn_clf.predict(X_test)\n",
    "print classification_report(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
