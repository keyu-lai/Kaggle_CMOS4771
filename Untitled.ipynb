{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bleding train set and valid set...\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "            oob_score=False, random_state=398, verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8f09d3c3bdbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-8f09d3c3bdbd>\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblend_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/Kaggle_CMOS4771/classifier.pyc\u001b[0m in \u001b[0;36mblend_clf\u001b[1;34m(clfs, data, quiz, label)\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[1;31m#train each mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m             \u001b[1;31m#model selection on validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mdataset_blend_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 290\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "from classifier import blend_clf, write_out, encode_label\n",
    "\n",
    "def prepare_data(df):\n",
    "    df4 = df\n",
    "    df1 = pd.DataFrame(df.loc[:,[u'0',u'5',u'7',u'8',u'9',u'14',u'16',u'17',u'56',u'57']])\n",
    "    #0 , 26 8, 5 , 14, 23 , 58 -> boss\n",
    "    #17, 56, 16,9,, 25, 57 -> yes\n",
    "    #20, 18, 7 -> no\n",
    "    #df2 = pd.DataFrame(df.loc[:,[u'18',u'20',u'23',u'25',u'26']])\n",
    "    df2 = pd.DataFrame(df.loc[:,[u'18',u'20',u'23',u'25',u'26',u'58']])\n",
    "    df3 = pd.DataFrame(df.drop([u'0',u'5',u'7',u'8',u'9',u'14',u'16',u'17',\n",
    "                          u'18',u'20',u'23',u'25',u'26',u'56',u'57',u'58'],axis=1))\n",
    "    \n",
    "    return df1, df2, df3, df4\n",
    "\n",
    "def encode(dataset):\n",
    "    drop_cols = []\n",
    "    for i in dataset.columns:\n",
    "        if isinstance(dataset[i].values[0], basestring):\n",
    "            drop_cols = drop_cols + [i]\n",
    "    \n",
    "    return encode_label(dataset, drop_cols)\n",
    "\n",
    "def encode_with_test(train, test):\n",
    "    agg_data = pd.concat([train, test],axis=0,ignore_index=True)\n",
    "    agg_data= encode(agg_data)\n",
    "    \n",
    "    return agg_data._slice(slice(0,train.shape[0]),axis=0), agg_data._slice(slice(train.shape[0],agg_data.shape[0]),axis=0)\n",
    "\n",
    "\n",
    "def run_local():\n",
    "    train = pd.read_csv('data.csv')\n",
    "    label = train['label']\n",
    "    train = train.drop('label',1)\n",
    "    train = encode(train)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.1)\n",
    "\n",
    "    clfs = [RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='gini', random_state=398, max_features='sqrt'),\n",
    "            ExtraTreesClassifier(n_estimators=200, n_jobs=-1, criterion='gini', max_features=None, random_state=312),\n",
    "            DecisionTreeClassifier(criterion='entropy',splitter='best')]\n",
    "\n",
    "\n",
    "    predictions = blend_clf(clfs, X_train.as_matrix(),X_test.as_matrix(),y_train.as_matrix())\n",
    "    print classification_report(y_test, predictions,digits=4)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "run_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from classifier import encode_onehot, encode_label\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def prepare_data(df):\n",
    "    df3 = df\n",
    "    df1 = pd.DataFrame(df.loc[:,[u'27',u'28',u'29',u'30',\n",
    "                                 u'31',u'32',u'33',u'34',\n",
    "                                 u'35',u'36',u'37',u'38',\n",
    "                                 u'39',u'40',u'41',u'42',\n",
    "                                 u'43',u'44',u'45',u'46',\n",
    "                                 u'47',u'48',u'49',u'50',\n",
    "                                 u'51',u'52',u'53',u'54',\n",
    "                                 u'55']])\n",
    "    #0 , 26 8, 5 , 14, 23 , 58 -> boss\n",
    "    #17, 56, 16,9,, 25, 57 -> yes\n",
    "    #20, 18, 7 -> no\n",
    "    #df2 = pd.DataFrame(df.loc[:,[u'18',u'20',u'23',u'25',u'26']])\n",
    "    df2 = pd.DataFrame(df.drop([u'27',u'28',u'29',u'30',\n",
    "                                 u'31',u'32',u'33',u'34',\n",
    "                                 u'35',u'36',u'37',u'38',\n",
    "                                 u'39',u'40',u'41',u'42',\n",
    "                                 u'43',u'44',u'45',u'46',\n",
    "                                 u'47',u'48',u'49',u'50',\n",
    "                                 u'51',u'52',u'53',u'54',\n",
    "                                 u'55'],axis=1))\n",
    "    \n",
    "    return df1, df2, df3\n",
    "\n",
    "def encode(dataset):\n",
    "    drop_cols = []\n",
    "    for i in dataset.columns:\n",
    "        if isinstance(dataset[i].values[0], basestring):\n",
    "            drop_cols = drop_cols + [i]\n",
    "    \n",
    "    return encode_label(dataset, drop_cols)\n",
    "\n",
    "def encode_with_test(train, test):\n",
    "    agg_data = pd.concat([train, test],axis=0,ignore_index=True)\n",
    "    agg_data= encode(agg_data)\n",
    "    \n",
    "    return agg_data._slice(slice(0,train.shape[0]),axis=0), agg_data._slice(slice(train.shape[0],agg_data.shape[0]),axis=0)\n",
    "\n",
    "train = pd.read_csv('data.csv')\n",
    "label = train['label']\n",
    "train = train.drop('label',1)\n",
    "print len(train.columns)\n",
    "X_quiz = pd.read_csv('quiz.csv')\n",
    "\n",
    "#split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label)\n",
    "train_1, train_2, train_all = prepare_data(X_train)\n",
    "test_1, test_2, test_all = prepare_data(X_test)\n",
    "quiz_1, quiz_2, quiz_all = prepare_data(X_quiz)\n",
    "                             \n",
    "#agg_data = pd.concat([train, X_quiz],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "#display(agg_data.shape[0])\n",
    "#train = agg_data._slice(slice(0,train.shape[0]),0)\n",
    "#X_quiz = agg_data._slice(slice(train.shape[0],agg_data.shape[0]),0)\n",
    "#pca = PCA(n_components=100)\n",
    "#train = pca.fit(train).transform(train)\n",
    "#display(train.shape)\n",
    "#display(X_quiz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95127, 52)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.9385    0.9664    0.9522      5444\n",
      "          1     0.9532    0.9152    0.9338      4069\n",
      "\n",
      "avg / total     0.9447    0.9445    0.9443      9513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from classifier import train_rf, train_gbc, train_ada_boost\n",
    "\n",
    "\n",
    "print train_1.shape\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train, test_size=0.1)\n",
    "\n",
    "sgd = SGDClassifier(loss=\"perceptron\", penalty=\"l2\",shuffle=True,alpha=0.00001,epsilon=0.01, verbose=100, random_state = 123)\n",
    "gbc = GradientBoostingClassifier(loss='deviance',random_state=0,n_estimators=200,learning_rate=0.05,max_depth=7)\n",
    "svm = SVC(kernel='linear', C=0.3)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=1, random_state=123, max_features='sqrt')\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features=None,random_state=0)\n",
    "adaBoost = AdaBoostClassifier(n_estimators=200, learning_rate=0.4)\n",
    "gnb = BernoulliNB()\n",
    "dt = DecisionTreeClassifier(criterion='entropy',splitter='best')\n",
    "nn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "adt = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_jobs=-1, n_estimators=10, min_samples_split=1, random_state=123),\n",
    "                    n_estimators=50, learning_rate=0.5)\n",
    "    \n",
    "clf = adt.fit(X_train1,y_train1)\n",
    "predictions = clf.predict(X_test1)\n",
    "print classification_report(y_test1, predictions, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95127, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   13.4s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:337: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   13.9s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   14.5s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   14.6s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   27.7s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   31.1s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   32.4s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   44.0s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   46.3s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   46.9s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   49.0s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   50.3s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   52.7s finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.2min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.3min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.4min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   53.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.6min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.py:621: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for i in range(n_jobs))\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  7.6min finished\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   37.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.934\n",
      "Best parameters set:\n",
      "\tclf__max_samples: 1.0\n",
      "\tclf__n_estimators: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1     0.9414    0.9563    0.9488      5406\n",
      "          1     0.9413    0.9216    0.9313      4107\n",
      "\n",
      "avg / total     0.9413    0.9413    0.9413      9513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier\n",
    "from classifier import train_xtree_classifer, train_rf, train_SGD_SVM, train_friedman_xgbm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from classifier import train_bagging_decision_tree\n",
    "## XTREE is extremely effective to Set 1\n",
    "display(train_1.shape)\n",
    "train_1 = encode(X_train)\n",
    "\n",
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\",shuffle=True,alpha=0.001,epsilon=0, verbose=1,n_iter=1)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train, test_size=0.1)\n",
    "bnn = BaggingClassifier(KNeighborsClassifier(), n_jobs=-1,random_state=851,n_estimators=50)\n",
    "bnn = BaggingClassifier(DecisionTreeClassifier(), n_jobs=-1,random_state=851,n_estimators=100)\n",
    "bnn = BaggingClassifier(sgd, n_jobs=-1,random_state=851,n_estimators=200)\n",
    "\n",
    "\n",
    "bnn = train_bagging_decision_tree(X_train1, y_train1)\n",
    "predictions = bnn.predict(X_test1)\n",
    "print classification_report(y_test1, predictions,digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-174659ce92e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mxtree\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'exponential'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mxtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1025\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1078\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1079\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 784\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "\n",
    "xtree =GradientBoostingClassifier(loss='exponential',n_estimators=300, learning_rate=0.1, random_state=0, subsample=0.2)\n",
    "\n",
    "xtree.fit(X_train1, y_train1)\n",
    "predictions = xtree.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.92      0.82      0.87      1077\n",
      "          1       0.79      0.91      0.84       798\n",
      "\n",
      "avg / total       0.86      0.85      0.86      1875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "mnb = BernoulliNB(alpha=0.55)\n",
    "\n",
    "mnb.fit(X_train1, y_train1)\n",
    "predictions = mnb.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 283.75, NNZs: 1552, Bias: -325.804089, T: 5625, Avg. loss: 5116.524409\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 220.87, NNZs: 1723, Bias: -323.304354, T: 11250, Avg. loss: 2951.077713\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 199.60, NNZs: 1797, Bias: -318.536513, T: 16875, Avg. loss: 2127.927144\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 187.99, NNZs: 1829, Bias: -313.307615, T: 22500, Avg. loss: 1678.605825\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 177.47, NNZs: 1853, Bias: -309.229986, T: 28125, Avg. loss: 1391.691489\n",
      "Total training time: 0.12 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.96      0.84      1120\n",
      "          1       0.89      0.50      0.64       755\n",
      "\n",
      "avg / total       0.80      0.77      0.76      1875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\",shuffle=True,alpha=0.001,epsilon=0.5, verbose=1)\n",
    "\n",
    "sgd.fit(X_train1,y_train1)\n",
    "predictions = sgd.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2521.11, NNZs: 1558, Bias: -1471.580604, T: 5625, Avg. loss: 26702.512751\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2190.95, NNZs: 1744, Bias: -1535.015508, T: 11250, Avg. loss: 17262.810969\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1989.69, NNZs: 1830, Bias: -1540.604594, T: 16875, Avg. loss: 13036.384057\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1860.46, NNZs: 1870, Bias: -1516.497241, T: 22500, Avg. loss: 10577.067978\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1751.77, NNZs: 1908, Bias: -1489.447623, T: 28125, Avg. loss: 8916.537499\n",
      "Total training time: 0.12 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.91      0.87      0.89      1120\n",
      "          1       0.82      0.87      0.84       755\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "mnb = BernoulliNB(alpha=0.55)\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "sgd = SGDClassifier(loss=\"log\", penalty=\"l2\",shuffle=True,alpha=0.0001,epsilon=0.1, verbose=1)\n",
    "\n",
    "votes = VotingClassifier(estimators=[('mnb', mnb), ('xtree', xtree),('sgd',sgd)] , voting='soft')\n",
    "votes.fit(X_train1,y_train1)\n",
    "predictions = votes.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
