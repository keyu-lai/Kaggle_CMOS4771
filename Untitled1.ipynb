{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "52\n",
      "(126837, 52) (95127, 10) (95127, 6) (95127, 36)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from classifier import encode_onehot\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def prepare_data(df):\n",
    "    df1 = pd.DataFrame(df.loc[:,[u'0',u'5',u'7',u'8',u'9',u'14',u'16',u'17',u'56',u'57']])\n",
    "    #0 , 26 8, 5 , 14, 23 , 58 -> boss\n",
    "    #17, 56, 16,9,, 25, 57 -> yes\n",
    "    #20, 18, 7 -> no\n",
    "    #df2 = pd.DataFrame(df.loc[:,[u'18',u'20',u'23',u'25',u'26']])\n",
    "    df2 = pd.DataFrame(df.loc[:,[u'18',u'20',u'23',u'25',u'26',u'58']])\n",
    "    df3 = pd.DataFrame(df.drop([u'0',u'5',u'7',u'8',u'9',u'14',u'16',u'17',\n",
    "                          u'18',u'20',u'23',u'25',u'26',u'56',u'57',u'58'],axis=1))\n",
    "    \n",
    "    return df1, df2, df3\n",
    "\n",
    "def encode(dataset):\n",
    "    drop_cols = []\n",
    "    for i in dataset.columns:\n",
    "        if isinstance(dataset[i].values[0], basestring):\n",
    "            drop_cols = drop_cols + [i]\n",
    "    \n",
    "    return encode_onehot(dataset, drop_cols)\n",
    "\n",
    "def encode_with_test(train, test):\n",
    "    agg_data = pd.concat([train, test],axis=0,ignore_index=True)\n",
    "    agg_data= encode(agg_data)\n",
    "    \n",
    "    return agg_data._slice(slice(0,train.shape[0]),axis=0), agg_data._slice(slice(train.shape[0],agg_data.shape[0]),axis=0)\n",
    "\n",
    "train = pd.read_csv('data.csv')\n",
    "label = train['label']\n",
    "train = train.drop('label',1)\n",
    "print len(train.columns)\n",
    "X_quiz = pd.read_csv('quiz.csv')\n",
    "\n",
    "#split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label)\n",
    "train_1, train_2, train_3 = prepare_data(X_train)\n",
    "test_1, test_2, test_3 = prepare_data(X_test)\n",
    "quiz_1, quiz_2, quiz_3 = prepare_data(X_quiz)\n",
    "                             \n",
    "\n",
    "#agg_data = pd.concat([train, X_quiz],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "#display(agg_data.shape[0])\n",
    "#train = agg_data._slice(slice(0,train.shape[0]),0)\n",
    "#X_quiz = agg_data._slice(slice(train.shape[0],agg_data.shape[0]),0)\n",
    "#pca = PCA(n_components=100)\n",
    "#train = pca.fit(train).transform(train)\n",
    "#display(train.shape)\n",
    "#display(X_quiz.shape)\n",
    "\n",
    "print len(train_1.columns) + len(train_2.columns) + len(train_3.columns)\n",
    "print train.shape, train_1.shape, train_2.shape, train_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.91      0.90      0.90      1031\n",
      "          1       0.88      0.89      0.89       844\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "train_1 = encode(train_1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "\n",
    "sgd = SGDClassifier(loss=\"log\", penalty=\"l2\",shuffle=True,alpha=0.0001,epsilon=0.1, verbose=1)\n",
    "gbc = GradientBoostingClassifier(loss='deviance',random_state=0,n_estimators=500,learning_rate=0.05,max_depth=7)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=1, random_state=0)\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "adaBoost = AdaBoostClassifier(base_estimator=xtree, n_estimators=200)\n",
    "\n",
    "svm = SVC(kernel='linear', C=0.05, probability=True)\n",
    "#svm = LinearSVC(penalty='l2', loss='hinge', dual=True, tol=0.0001, C=0.05, \n",
    "#                random_state=123)\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0)\n",
    "\n",
    "votes = VotingClassifier(estimators=[('svm', svm), ('xtree', xtree)], voting='soft')\n",
    "\n",
    "votes.fit(X_train1,y_train1)\n",
    "predictions = votes.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95127, 52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import classifier\n",
    "reload(classifier)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from classifier import train_xtree_classifer, train_rf, train_SGD_SVM, train_friedman_xgbm\n",
    "from sklearn.metrics import classification_report\n",
    "## XTREE is extremely effective to Set 1\n",
    "display(X_train.shape)\n",
    "train_1 = encode(X_train)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_1, y_train)\n",
    "\n",
    "xtree = ExtraTreesClassifier(n_jobs=-1,n_estimators=200,max_depth=None, max_features='sqrt',random_state=0,\n",
    "                             warm_start=True, bootstrap=True, criterion='entropy')\n",
    "svm = SVC(kernel='linear', C=0.05, probability=True)\n",
    "\n",
    "votes = VotingClassifier(estimators=[('svm', svm), ('xtree', xtree)], voting='soft')\n",
    "\n",
    "\n",
    "votes.fit(X_train1, y_train1)\n",
    "predictions = votes.predict(X_test1)\n",
    "print classification_report(y_test1, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
